{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlSS96RwlFrT"
      },
      "source": [
        "**How to run this script?**\n",
        "\n",
        "\n",
        "1.   Navigate to \"**Load the pretrained model**\" section and set the path \n",
        "where you located the Bayesian models. \n",
        "2.   Navigate to \"**Simulations**\" section and provide a location where you want to save the model output. \n",
        "3. You are all set! Now you can run the script on Google Colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H4JAgS4o3mg5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyro-ppl==0.2.1 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (0.2.1)\n",
            "Requirement already satisfied: contextlib2 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (21.6.0)\n",
            "Requirement already satisfied: graphviz>=0.8 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (0.20.3)\n",
            "Requirement already satisfied: networkx>=2.0.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (3.1)\n",
            "Requirement already satisfied: numpy>=1.7 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (1.24.4)\n",
            "Requirement already satisfied: six>=1.10.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (1.16.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (2.4.0+cu124)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (4.12.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (3.15.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (3.1.4)\n",
            "Requirement already satisfied: sympy in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (1.13.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from jinja2->torch>=0.4.0->pyro-ppl==0.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from sympy->torch>=0.4.0->pyro-ppl==0.2.1) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.1.1; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyro-ppl==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N6jMxsF_xVp4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rmEFaPL30Sh",
        "outputId": "be7edb3c-4c64-4210-e816-ac01fe32769a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Check Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0DJT0xeAqXL"
      },
      "source": [
        "**Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tTRmzMB4yMxj"
      },
      "outputs": [],
      "source": [
        "AlexTransform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(os.path.join(\"..\", \"data\",'mnist-data'), train=True, download=True, transform=AlexTransform),\n",
        "        batch_size=500, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(os.path.join(\"..\", \"data\",'mnist-data'), train=False, download=True, transform=AlexTransform),\n",
        "        batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyqaSFcs3Udj"
      },
      "source": [
        "**Define the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4QqsElxSF2F"
      },
      "source": [
        "AlexNet structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XNBayOSDyyn9"
      },
      "outputs": [],
      "source": [
        "# AlexNet\n",
        "class alexnet(nn.Module):  \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = self.fc3(out)\n",
        "        # out = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l-94O5iW367h"
      },
      "outputs": [],
      "source": [
        "# Define Hyper parameters\n",
        "img_size = 28 * 28\n",
        "hidden_layer_size = 1024\n",
        "num_classes = 10\n",
        "net = alexnet().to(device)\n",
        "# softmax\n",
        "log_softmax = nn.LogSoftmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COLZgZNISK4g"
      },
      "source": [
        "Model function for pyro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "liRRzYaD4Ejg"
      },
      "outputs": [],
      "source": [
        "def model(x_data, y_data):\n",
        "\n",
        "    convLayer1_w = Normal(loc=torch.ones_like(net.conv1[0].weight), scale=torch.ones_like(net.conv1[0].weight))\n",
        "    convLayer1_b = Normal(loc=torch.ones_like(net.conv1[0].bias), scale=torch.ones_like(net.conv1[0].bias))\n",
        "\n",
        "    convLayer2_w = Normal(loc=torch.ones_like(net.conv2[0].weight), scale=torch.ones_like(net.conv2[0].weight))\n",
        "    convLayer2_b = Normal(loc=torch.ones_like(net.conv2[0].bias), scale=torch.ones_like(net.conv2[0].bias))\n",
        "\n",
        "    convLayer3_w = Normal(loc=torch.ones_like(net.conv3[0].weight), scale=torch.ones_like(net.conv3[0].weight))\n",
        "    convLayer3_b = Normal(loc=torch.ones_like(net.conv3[0].bias), scale=torch.ones_like(net.conv3[0].bias))\n",
        "\n",
        "    convLayer4_w = Normal(loc=torch.ones_like(net.conv4[0].weight), scale=torch.ones_like(net.conv4[0].weight))\n",
        "    convLayer4_b = Normal(loc=torch.ones_like(net.conv4[0].bias), scale=torch.ones_like(net.conv4[0].bias))\n",
        "\n",
        "    convLayer5_w = Normal(loc=torch.ones_like(net.conv5[0].weight), scale=torch.ones_like(net.conv5[0].weight))\n",
        "    convLayer5_b = Normal(loc=torch.ones_like(net.conv5[0].bias), scale=torch.ones_like(net.conv5[0].bias))\n",
        "\n",
        "    fc1Layer_w = Normal(loc=torch.ones_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
        "    fc1Layer_b = Normal(loc=torch.ones_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
        "\n",
        "    fc2Layer_w = Normal(loc=torch.ones_like(net.fc2.weight), scale=torch.ones_like(net.fc2.weight))\n",
        "    fc2Layer_b = Normal(loc=torch.ones_like(net.fc2.bias), scale=torch.ones_like(net.fc2.bias))\n",
        "\n",
        "    fc3Layer_w = Normal(loc=torch.ones_like(net.fc3.weight), scale=torch.ones_like(net.fc3.weight))\n",
        "    fc3Layer_b = Normal(loc=torch.ones_like(net.fc3.bias), scale=torch.ones_like(net.fc3.bias))\n",
        "\n",
        "    priors = {'conv1[0].weight': convLayer1_w, \n",
        "              'conv1[0].bias': convLayer1_b,\n",
        "              'conv2[0].weight': convLayer2_w,\n",
        "              'conv2[0].bias': convLayer2_b,\n",
        "              'conv3[0].weight': convLayer3_w,\n",
        "              'conv3[0].bias': convLayer3_b,\n",
        "              'conv4[0].weight': convLayer4_w,\n",
        "              'conv4[0].bias': convLayer4_b,\n",
        "              'conv5[0].weight': convLayer5_w,\n",
        "              'conv5[0].bias': convLayer5_b,\n",
        "              'fc1.weight': fc1Layer_w, \n",
        "              'fc1.bias': fc1Layer_b,\n",
        "              'fc2.weight': fc2Layer_w, \n",
        "              'fc2.bias': fc2Layer_b,\n",
        "              'fc3.weight': fc3Layer_w, \n",
        "              'fc3.bias': fc3Layer_b}\n",
        "\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    # sample a regressor (which also samples w and b)\n",
        "    lifted_reg_model = lifted_module()\n",
        "\n",
        "    lhat = log_softmax(lifted_reg_model(x_data))\n",
        "\n",
        "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4OnUndST19"
      },
      "source": [
        "Guide function for pyro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "So18-_z_4Hv3"
      },
      "outputs": [],
      "source": [
        "softplus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "    \n",
        "    # First layer weight distribution priors\n",
        "    convLayer1w_mu    = torch.randn_like(net.conv1[0].weight)\n",
        "    convLayer1w_sigma = torch.randn_like(net.conv1[0].weight)\n",
        "    convLayer1w_mu_param    = pyro.param(\"convLayer1w_mu\", convLayer1w_mu)\n",
        "    convLayer1w_sigma_param = softplus(pyro.param(\"convLayer1w_sigma\", convLayer1w_sigma))\n",
        "    convLayer1_w = Normal(loc=convLayer1w_mu_param, scale=convLayer1w_sigma_param)\n",
        "\n",
        "    # First layer bias distribution priors\n",
        "    convLayer1b_mu    = torch.randn_like(net.conv1[0].bias)\n",
        "    convLayer1b_sigma = torch.randn_like(net.conv1[0].bias)\n",
        "    convLayer1b_mu_param    = pyro.param(\"convLayer1b_mu\", convLayer1b_mu)\n",
        "    convLayer1b_sigma_param = softplus(pyro.param(\"convLayer1b_sigma\", convLayer1b_sigma))\n",
        "    convLayer1_b = Normal(loc=convLayer1b_mu_param, scale=convLayer1b_sigma_param)\n",
        "\n",
        "    # Second layer weight distribution priors\n",
        "    convLayer2w_mu    = torch.randn_like(net.conv2[0].weight)\n",
        "    convLayer2w_sigma = torch.randn_like(net.conv2[0].weight)\n",
        "    convLayer2w_mu_param    = pyro.param(\"convLayer2w_mu\", convLayer2w_mu)\n",
        "    convLayer2w_sigma_param = softplus(pyro.param(\"convLayer2w_sigma\", convLayer2w_sigma))\n",
        "    convLayer2_w = Normal(loc=convLayer2w_mu_param, scale=convLayer2w_sigma_param)\n",
        "\n",
        "    # Second layer bias distribution priors\n",
        "    convLayer2b_mu    = torch.randn_like(net.conv2[0].bias)\n",
        "    convLayer2b_sigma = torch.randn_like(net.conv2[0].bias)\n",
        "    convLayer2b_mu_param    = pyro.param(\"convLayer2b_mu\", convLayer2b_mu)\n",
        "    convLayer2b_sigma_param = softplus(pyro.param(\"convLayer2b_sigma\", convLayer2b_sigma))\n",
        "    convLayer2_b = Normal(loc=convLayer2b_mu_param, scale=convLayer2b_sigma_param)\n",
        "\n",
        "    # Third layer weight distribution priors\n",
        "    convLayer3w_mu    = torch.randn_like(net.conv3[0].weight)\n",
        "    convLayer3w_sigma = torch.randn_like(net.conv3[0].weight)\n",
        "    convLayer3w_mu_param    = pyro.param(\"convLayer3w_mu\", convLayer3w_mu)\n",
        "    convLayer3w_sigma_param = softplus(pyro.param(\"convLayer3w_sigma\", convLayer3w_sigma))\n",
        "    convLayer3_w = Normal(loc=convLayer3w_mu_param, scale=convLayer3w_sigma_param)\n",
        "\n",
        "    # Third layer bias distribution priors\n",
        "    convLayer3b_mu    = torch.randn_like(net.conv3[0].bias)\n",
        "    convLayer3b_sigma = torch.randn_like(net.conv3[0].bias)\n",
        "    convLayer3b_mu_param    = pyro.param(\"convLayer3b_mu\", convLayer3b_mu)\n",
        "    convLayer3b_sigma_param = softplus(pyro.param(\"convLayer3b_sigma\", convLayer3b_sigma))\n",
        "    convLayer3_b = Normal(loc=convLayer3b_mu_param, scale=convLayer3b_sigma_param)\n",
        "\n",
        "    # Fourth layer weight distribution priors\n",
        "    convLayer4w_mu    = torch.randn_like(net.conv4[0].weight)\n",
        "    convLayer4w_sigma = torch.randn_like(net.conv4[0].weight)\n",
        "    convLayer4w_mu_param    = pyro.param(\"convLayer4w_mu\", convLayer4w_mu)\n",
        "    convLayer4w_sigma_param = softplus(pyro.param(\"convLayer4w_sigma\", convLayer4w_sigma))\n",
        "    convLayer4_w = Normal(loc=convLayer4w_mu_param, scale=convLayer4w_sigma_param)\n",
        "\n",
        "    # Fourth layer bias distribution priors\n",
        "    convLayer4b_mu    = torch.randn_like(net.conv4[0].bias)\n",
        "    convLayer4b_sigma = torch.randn_like(net.conv4[0].bias)\n",
        "    convLayer4b_mu_param    = pyro.param(\"convLayer4b_mu\", convLayer4b_mu)\n",
        "    convLayer4b_sigma_param = softplus(pyro.param(\"convLayer4b_sigma\", convLayer4b_sigma))\n",
        "    convLayer4_b = Normal(loc=convLayer4b_mu_param, scale=convLayer4b_sigma_param)\n",
        "\n",
        "    # Fifth layer weight distribution priors\n",
        "    convLayer5w_mu    = torch.randn_like(net.conv5[0].weight)\n",
        "    convLayer5w_sigma = torch.randn_like(net.conv5[0].weight)\n",
        "    convLayer5w_mu_param    = pyro.param(\"convLayer5w_mu\", convLayer5w_mu)\n",
        "    convLayer5w_sigma_param = softplus(pyro.param(\"convLayer5w_sigma\", convLayer5w_sigma))\n",
        "    convLayer5_w = Normal(loc=convLayer5w_mu_param, scale=convLayer5w_sigma_param)\n",
        "\n",
        "    # Fifth layer bias distribution priors\n",
        "    convLayer5b_mu    = torch.randn_like(net.conv5[0].bias)\n",
        "    convLayer5b_sigma = torch.randn_like(net.conv5[0].bias)\n",
        "    convLayer5b_mu_param    = pyro.param(\"convLayer5b_mu\", convLayer5b_mu)\n",
        "    convLayer5b_sigma_param = softplus(pyro.param(\"convLayer5b_sigma\", convLayer5b_sigma))\n",
        "    convLayer5_b = Normal(loc=convLayer5b_mu_param, scale=convLayer5b_sigma_param)\n",
        "\n",
        "    # First fully connected layer weight distribution priors\n",
        "    fc1w_mu = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
        "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
        "    fc1Layer_w = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param).independent(1)\n",
        "\n",
        "    # First fully connected layer bias distribution priors\n",
        "    fc1b_mu = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
        "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
        "    fc1Layer_b = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
        "\n",
        "    # Second fully connected layer weight distribution priors\n",
        "    fc2w_mu = torch.randn_like(net.fc2.weight)\n",
        "    fc2w_sigma = torch.randn_like(net.fc2.weight)\n",
        "    fc2w_mu_param = pyro.param(\"fc2w_mu\", fc2w_mu)\n",
        "    fc2w_sigma_param = softplus(pyro.param(\"fc2w_sigma\", fc2w_sigma))\n",
        "    fc2Layer_w = Normal(loc=fc2w_mu_param, scale=fc2w_sigma_param).independent(1)\n",
        "\n",
        "    # Second fully connected layer bias distribution priors\n",
        "    fc2b_mu = torch.randn_like(net.fc2.bias)\n",
        "    fc2b_sigma = torch.randn_like(net.fc2.bias)\n",
        "    fc2b_mu_param = pyro.param(\"fc2b_mu\", fc2b_mu)\n",
        "    fc2b_sigma_param = softplus(pyro.param(\"fc2b_sigma\", fc2b_sigma))\n",
        "    fc2Layer_b = Normal(loc=fc2b_mu_param, scale=fc2b_sigma_param)\n",
        "\n",
        "    # Third fully connected layer weight distribution priors\n",
        "    fc3w_mu = torch.randn_like(net.fc3.weight)\n",
        "    fc3w_sigma = torch.randn_like(net.fc3.weight)\n",
        "    fc3w_mu_param = pyro.param(\"fc3w_mu\", fc3w_mu)\n",
        "    fc3w_sigma_param = softplus(pyro.param(\"fc3w_sigma\", fc3w_sigma))\n",
        "    fc3Layer_w = Normal(loc=fc3w_mu_param, scale=fc3w_sigma_param).independent(1)\n",
        "\n",
        "    # Third fully connected layer bias distribution priors\n",
        "    fc3b_mu = torch.randn_like(net.fc3.bias)\n",
        "    fc3b_sigma = torch.randn_like(net.fc3.bias)\n",
        "    fc3b_mu_param = pyro.param(\"fc3b_mu\", fc3b_mu)\n",
        "    fc3b_sigma_param = softplus(pyro.param(\"fc3b_sigma\", fc3b_sigma))\n",
        "    fc3Layer_b = Normal(loc=fc3b_mu_param, scale=fc3b_sigma_param)\n",
        "\n",
        "    priors = {'conv1[0].weight': convLayer1_w, \n",
        "              'conv1[0].bias': convLayer1_b,\n",
        "              'conv2[0].weight': convLayer2_w,\n",
        "              'conv2[0].bias': convLayer2_b,\n",
        "              'conv3[0].weight': convLayer3_w,\n",
        "              'conv3[0].bias': convLayer3_b,\n",
        "              'conv4[0].weight': convLayer4_w,\n",
        "              'conv4[0].bias': convLayer4_b,\n",
        "              'conv5[0].weight': convLayer5_w,\n",
        "              'conv5[0].bias': convLayer5_b,\n",
        "              'fc1.weight': fc1Layer_w, \n",
        "              'fc1.bias': fc1Layer_b,\n",
        "              'fc2.weight': fc2Layer_w, \n",
        "              'fc2.bias': fc2Layer_b,\n",
        "              'fc3.weight': fc3Layer_w, \n",
        "              'fc3.bias': fc3Layer_b}\n",
        "\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    \n",
        "    return lifted_module()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkWj6hP7m5Wb"
      },
      "source": [
        "**Load the pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SjXvlXSz4KXG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tomva\\AppData\\Local\\Temp\\ipykernel_26008\\2903089453.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  saved_model_dict = torch.load(model_path + '\\model_01.pt') # model #1 in the path\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "Can't get attribute 'guide' on <module '__main__'>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#model_path = 'Bayesian models/' # This should be the path where the models are located\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m saved_model_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodel_01.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# model #1 in the path\u001b[39;00m\n\u001b[0;32m      3\u001b[0m net\u001b[38;5;241m.\u001b[39mload_state_dict(saved_model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m guide \u001b[38;5;241m=\u001b[39m saved_model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mguide\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\tomva\\OneDrive\\KU Leuven\\Master Theory and Research\\Internship\\RTNet\\venv\\lib\\site-packages\\torch\\serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\tomva\\OneDrive\\KU Leuven\\Master Theory and Research\\Internship\\RTNet\\venv\\lib\\site-packages\\torch\\serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[0;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
            "File \u001b[1;32mc:\\Users\\tomva\\OneDrive\\KU Leuven\\Master Theory and Research\\Internship\\RTNet\\venv\\lib\\site-packages\\torch\\serialization.py:1515\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'guide' on <module '__main__'>"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(\"..\", \"data\", \"Bayesian models\") # This should be the path where the models are located\n",
        "saved_model_dict = torch.load(model_path + '\\model_01.pt') # model #1 in the path\n",
        "net.load_state_dict(saved_model_dict['model'])\n",
        "guide = saved_model_dict['guide']\n",
        "pyro.get_param_store().load(model_path + \"\\model_01_params.pt\") # model #1 in the path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcMyqXVQR7l2"
      },
      "source": [
        "**Define utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "04cayGzoe4zC"
      },
      "outputs": [],
      "source": [
        "def give_uncertainities(x, num_samples=1):\n",
        "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
        "    yhats = [F.log_softmax(model(x).data, dim=1) for model in sampled_models]\n",
        "    return yhats[0]\n",
        "\n",
        "def compute_evidence(image):\n",
        "    # image = image.unsqueeze(dim=0)\n",
        "    y = give_uncertainities(image)\n",
        "    return y\n",
        "\n",
        "def compute_confidence(evidence):\n",
        "    conf = torch.exp(evidence)\n",
        "    conf = conf / torch.sum(conf)\n",
        "    conf_diff = conf.sort().values[0][-1] - conf.sort().values[0][-2]\n",
        "    return conf_diff, conf\n",
        "\n",
        "\n",
        "def decide(image, threshold=10):\n",
        "    rt = 0\n",
        "    max_evidence, total_evidence = 0, 0\n",
        "    while max_evidence < threshold:\n",
        "      evidence = torch.exp(compute_evidence(image))\n",
        "      total_evidence = total_evidence + evidence\n",
        "      max_evidence = torch.max(total_evidence)\n",
        "      rt = rt + 1\n",
        "    choice = torch.argmax(total_evidence)\n",
        "    confidence, confidence_array = compute_confidence(total_evidence)\n",
        "    return int(choice.cpu().numpy()), rt, float(confidence.cpu().numpy()), confidence_array.cpu().numpy()\n",
        "\n",
        "def save_df(index, Choice, RT, Confidence, Threshold, Noise, Labels, path):\n",
        "    simulations = {'mnist_index': index,\n",
        "                   'choice': Choice,\n",
        "                   'rt': RT,\n",
        "                   'confidence': Confidence,\n",
        "                   'threshold': Threshold,\n",
        "                   'noise': Noise,\n",
        "                   'true label': Labels}\n",
        "    df = pd.DataFrame(simulations)\n",
        "    df.to_csv(path)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlYwlVoYAWQn"
      },
      "source": [
        "**Simulations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3u7XgcKC4res"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set the threshold to 3\n",
            "   Set the noise level to 2.1\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the noise level to 2.9\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "Set the threshold to 5\n",
            "   Set the noise level to 2.1\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the noise level to 2.9\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "threshold_levels = [3, 5]\n",
        "noise_levels = [2.1, 2.9]\n",
        "save_path = os.path.join(\"..\", \"results\", \"simulations.csv\") # path to where you want to save the output\n",
        "all_i, all_choice, all_rt, all_confidence, all_threshold, all_labels, all_noise = [], [], [], [], [], []. []\n",
        "for a in threshold_levels:\n",
        "  print(\"Set the threshold to {}\".format(str(a)))\n",
        "  for noise in noise_levels:\n",
        "      print('   Set the noise level to {}'.format(str(noise)))\n",
        "      for i, (image, label) in enumerate(test_loader):\n",
        "        choice, rt, confidence, _ = decide((image + noise * torch.rand(image.shape)).to(device), threshold=a)\n",
        "        all_i.append(i)\n",
        "        all_choice.append(choice)\n",
        "        all_rt.append(rt)\n",
        "        all_confidence.append(confidence)\n",
        "        all_threshold.append(a)\n",
        "        all_noise.append(noise)\n",
        "        all_labels.append(int(label.cpu().numpy()))\n",
        "        if (i%1000)==0:\n",
        "          print('           {}'.format(str(i)))\n",
        "      save_df(all_i, all_choice, all_rt, all_confidence, all_threshold, all_noise, all_labels, save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

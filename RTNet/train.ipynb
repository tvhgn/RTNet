{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlSS96RwlFrT"
      },
      "source": [
        "### **Train a Bayesian model from scratch for MNIST using AlexNet architecture**\n",
        "\n",
        "The following notebook can be run on google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H4JAgS4o3mg5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyro-ppl==0.2.1 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (0.2.1)\n",
            "Requirement already satisfied: contextlib2 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (21.6.0)\n",
            "Requirement already satisfied: graphviz>=0.8 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (0.20.3)\n",
            "Requirement already satisfied: networkx>=2.0.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (3.1)\n",
            "Requirement already satisfied: numpy>=1.7 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (1.24.4)\n",
            "Requirement already satisfied: six>=1.10.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (1.16.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (2.4.0+cu124)\n",
            "Requirement already satisfied: fsspec in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (2024.6.1)\n",
            "Requirement already satisfied: sympy in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (3.1.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from jinja2->torch>=0.4.0->pyro-ppl==0.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from sympy->torch>=0.4.0->pyro-ppl==0.2.1) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.1.1; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyro-ppl==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N6jMxsF_xVp4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rmEFaPL30Sh",
        "outputId": "eb70bef7-0fad-4ffd-c8fc-d9bfe124febe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Check Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0DJT0xeAqXL"
      },
      "source": [
        "**Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tTRmzMB4yMxj"
      },
      "outputs": [],
      "source": [
        "AlexTransform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Path to mnist data\n",
        "mnist_data_path = os.path.join(\"..\", \"data\", 'mnist-data')\n",
        "\n",
        "# Create a loader for training data and testing data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(mnist_data_path, train=True, download=True, transform=AlexTransform),\n",
        "        batch_size=500, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(mnist_data_path, train=False, download=True, transform=AlexTransform),\n",
        "        batch_size=1, shuffle=False)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(mnist_data_path, train=False, download=True, transform=AlexTransform),\n",
        "        batch_size=500, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyqaSFcs3Udj"
      },
      "source": [
        "**Define the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4QqsElxSF2F"
      },
      "source": [
        "AlexNet structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XNBayOSDyyn9"
      },
      "outputs": [],
      "source": [
        "# AlexNet\n",
        "class alexnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = self.fc3(out)\n",
        "        # out = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l-94O5iW367h"
      },
      "outputs": [],
      "source": [
        "# Define Hyper parameters\n",
        "img_size = 28 * 28\n",
        "hidden_layer_size = 1024\n",
        "num_classes = 10\n",
        "net = alexnet().to(device)\n",
        "# softmax\n",
        "log_softmax = nn.LogSoftmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COLZgZNISK4g"
      },
      "source": [
        "Model function for pyro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "liRRzYaD4Ejg"
      },
      "outputs": [],
      "source": [
        "def model(x_data, y_data):\n",
        "\n",
        "    convLayer1_w = Normal(loc=torch.ones_like(net.conv1[0].weight), scale=torch.ones_like(net.conv1[0].weight))\n",
        "    convLayer1_b = Normal(loc=torch.ones_like(net.conv1[0].bias), scale=torch.ones_like(net.conv1[0].bias))\n",
        "\n",
        "    convLayer2_w = Normal(loc=torch.ones_like(net.conv2[0].weight), scale=torch.ones_like(net.conv2[0].weight))\n",
        "    convLayer2_b = Normal(loc=torch.ones_like(net.conv2[0].bias), scale=torch.ones_like(net.conv2[0].bias))\n",
        "\n",
        "    convLayer3_w = Normal(loc=torch.ones_like(net.conv3[0].weight), scale=torch.ones_like(net.conv3[0].weight))\n",
        "    convLayer3_b = Normal(loc=torch.ones_like(net.conv3[0].bias), scale=torch.ones_like(net.conv3[0].bias))\n",
        "\n",
        "    convLayer4_w = Normal(loc=torch.ones_like(net.conv4[0].weight), scale=torch.ones_like(net.conv4[0].weight))\n",
        "    convLayer4_b = Normal(loc=torch.ones_like(net.conv4[0].bias), scale=torch.ones_like(net.conv4[0].bias))\n",
        "\n",
        "    convLayer5_w = Normal(loc=torch.ones_like(net.conv5[0].weight), scale=torch.ones_like(net.conv5[0].weight))\n",
        "    convLayer5_b = Normal(loc=torch.ones_like(net.conv5[0].bias), scale=torch.ones_like(net.conv5[0].bias))\n",
        "\n",
        "    fc1Layer_w = Normal(loc=torch.ones_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
        "    fc1Layer_b = Normal(loc=torch.ones_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
        "\n",
        "    fc2Layer_w = Normal(loc=torch.ones_like(net.fc2.weight), scale=torch.ones_like(net.fc2.weight))\n",
        "    fc2Layer_b = Normal(loc=torch.ones_like(net.fc2.bias), scale=torch.ones_like(net.fc2.bias))\n",
        "\n",
        "    fc3Layer_w = Normal(loc=torch.ones_like(net.fc3.weight), scale=torch.ones_like(net.fc3.weight))\n",
        "    fc3Layer_b = Normal(loc=torch.ones_like(net.fc3.bias), scale=torch.ones_like(net.fc3.bias))\n",
        "\n",
        "    priors = {'conv1[0].weight': convLayer1_w,\n",
        "              'conv1[0].bias': convLayer1_b,\n",
        "              'conv2[0].weight': convLayer2_w,\n",
        "              'conv2[0].bias': convLayer2_b,\n",
        "              'conv3[0].weight': convLayer3_w,\n",
        "              'conv3[0].bias': convLayer3_b,\n",
        "              'conv4[0].weight': convLayer4_w,\n",
        "              'conv4[0].bias': convLayer4_b,\n",
        "              'conv5[0].weight': convLayer5_w,\n",
        "              'conv5[0].bias': convLayer5_b,\n",
        "              'fc1.weight': fc1Layer_w,\n",
        "              'fc1.bias': fc1Layer_b,\n",
        "              'fc2.weight': fc2Layer_w,\n",
        "              'fc2.bias': fc2Layer_b,\n",
        "              'fc3.weight': fc3Layer_w,\n",
        "              'fc3.bias': fc3Layer_b}\n",
        "\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    # sample a regressor (which also samples w and b)\n",
        "    lifted_reg_model = lifted_module()\n",
        "\n",
        "    lhat = log_softmax(lifted_reg_model(x_data))\n",
        "\n",
        "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4OnUndST19"
      },
      "source": [
        "Guide function for pyro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "So18-_z_4Hv3"
      },
      "outputs": [],
      "source": [
        "softplus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "\n",
        "    # First layer weight distribution priors\n",
        "    convLayer1w_mu    = torch.randn_like(net.conv1[0].weight)\n",
        "    convLayer1w_sigma = torch.randn_like(net.conv1[0].weight)\n",
        "    convLayer1w_mu_param    = pyro.param(\"convLayer1w_mu\", convLayer1w_mu)\n",
        "    convLayer1w_sigma_param = softplus(pyro.param(\"convLayer1w_sigma\", convLayer1w_sigma))\n",
        "    convLayer1_w = Normal(loc=convLayer1w_mu_param, scale=convLayer1w_sigma_param)\n",
        "\n",
        "    # First layer bias distribution priors\n",
        "    convLayer1b_mu    = torch.randn_like(net.conv1[0].bias)\n",
        "    convLayer1b_sigma = torch.randn_like(net.conv1[0].bias)\n",
        "    convLayer1b_mu_param    = pyro.param(\"convLayer1b_mu\", convLayer1b_mu)\n",
        "    convLayer1b_sigma_param = softplus(pyro.param(\"convLayer1b_sigma\", convLayer1b_sigma))\n",
        "    convLayer1_b = Normal(loc=convLayer1b_mu_param, scale=convLayer1b_sigma_param)\n",
        "\n",
        "    # Second layer weight distribution priors\n",
        "    convLayer2w_mu    = torch.randn_like(net.conv2[0].weight)\n",
        "    convLayer2w_sigma = torch.randn_like(net.conv2[0].weight)\n",
        "    convLayer2w_mu_param    = pyro.param(\"convLayer2w_mu\", convLayer2w_mu)\n",
        "    convLayer2w_sigma_param = softplus(pyro.param(\"convLayer2w_sigma\", convLayer2w_sigma))\n",
        "    convLayer2_w = Normal(loc=convLayer2w_mu_param, scale=convLayer2w_sigma_param)\n",
        "\n",
        "    # Second layer bias distribution priors\n",
        "    convLayer2b_mu    = torch.randn_like(net.conv2[0].bias)\n",
        "    convLayer2b_sigma = torch.randn_like(net.conv2[0].bias)\n",
        "    convLayer2b_mu_param    = pyro.param(\"convLayer2b_mu\", convLayer2b_mu)\n",
        "    convLayer2b_sigma_param = softplus(pyro.param(\"convLayer2b_sigma\", convLayer2b_sigma))\n",
        "    convLayer2_b = Normal(loc=convLayer2b_mu_param, scale=convLayer2b_sigma_param)\n",
        "\n",
        "    # Third layer weight distribution priors\n",
        "    convLayer3w_mu    = torch.randn_like(net.conv3[0].weight)\n",
        "    convLayer3w_sigma = torch.randn_like(net.conv3[0].weight)\n",
        "    convLayer3w_mu_param    = pyro.param(\"convLayer3w_mu\", convLayer3w_mu)\n",
        "    convLayer3w_sigma_param = softplus(pyro.param(\"convLayer3w_sigma\", convLayer3w_sigma))\n",
        "    convLayer3_w = Normal(loc=convLayer3w_mu_param, scale=convLayer3w_sigma_param)\n",
        "\n",
        "    # Third layer bias distribution priors\n",
        "    convLayer3b_mu    = torch.randn_like(net.conv3[0].bias)\n",
        "    convLayer3b_sigma = torch.randn_like(net.conv3[0].bias)\n",
        "    convLayer3b_mu_param    = pyro.param(\"convLayer3b_mu\", convLayer3b_mu)\n",
        "    convLayer3b_sigma_param = softplus(pyro.param(\"convLayer3b_sigma\", convLayer3b_sigma))\n",
        "    convLayer3_b = Normal(loc=convLayer3b_mu_param, scale=convLayer3b_sigma_param)\n",
        "\n",
        "    # Fourth layer weight distribution priors\n",
        "    convLayer4w_mu    = torch.randn_like(net.conv4[0].weight)\n",
        "    convLayer4w_sigma = torch.randn_like(net.conv4[0].weight)\n",
        "    convLayer4w_mu_param    = pyro.param(\"convLayer4w_mu\", convLayer4w_mu)\n",
        "    convLayer4w_sigma_param = softplus(pyro.param(\"convLayer4w_sigma\", convLayer4w_sigma))\n",
        "    convLayer4_w = Normal(loc=convLayer4w_mu_param, scale=convLayer4w_sigma_param)\n",
        "\n",
        "    # Fourth layer bias distribution priors\n",
        "    convLayer4b_mu    = torch.randn_like(net.conv4[0].bias)\n",
        "    convLayer4b_sigma = torch.randn_like(net.conv4[0].bias)\n",
        "    convLayer4b_mu_param    = pyro.param(\"convLayer4b_mu\", convLayer4b_mu)\n",
        "    convLayer4b_sigma_param = softplus(pyro.param(\"convLayer4b_sigma\", convLayer4b_sigma))\n",
        "    convLayer4_b = Normal(loc=convLayer4b_mu_param, scale=convLayer4b_sigma_param)\n",
        "\n",
        "    # Fifth layer weight distribution priors\n",
        "    convLayer5w_mu    = torch.randn_like(net.conv5[0].weight)\n",
        "    convLayer5w_sigma = torch.randn_like(net.conv5[0].weight)\n",
        "    convLayer5w_mu_param    = pyro.param(\"convLayer5w_mu\", convLayer5w_mu)\n",
        "    convLayer5w_sigma_param = softplus(pyro.param(\"convLayer5w_sigma\", convLayer5w_sigma))\n",
        "    convLayer5_w = Normal(loc=convLayer5w_mu_param, scale=convLayer5w_sigma_param)\n",
        "\n",
        "    # Fifth layer bias distribution priors\n",
        "    convLayer5b_mu    = torch.randn_like(net.conv5[0].bias)\n",
        "    convLayer5b_sigma = torch.randn_like(net.conv5[0].bias)\n",
        "    convLayer5b_mu_param    = pyro.param(\"convLayer5b_mu\", convLayer5b_mu)\n",
        "    convLayer5b_sigma_param = softplus(pyro.param(\"convLayer5b_sigma\", convLayer5b_sigma))\n",
        "    convLayer5_b = Normal(loc=convLayer5b_mu_param, scale=convLayer5b_sigma_param)\n",
        "\n",
        "    # First fully connected layer weight distribution priors\n",
        "    fc1w_mu = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
        "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
        "    fc1Layer_w = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param).independent(1)\n",
        "\n",
        "    # First fully connected layer bias distribution priors\n",
        "    fc1b_mu = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
        "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
        "    fc1Layer_b = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
        "\n",
        "    # Second fully connected layer weight distribution priors\n",
        "    fc2w_mu = torch.randn_like(net.fc2.weight)\n",
        "    fc2w_sigma = torch.randn_like(net.fc2.weight)\n",
        "    fc2w_mu_param = pyro.param(\"fc2w_mu\", fc2w_mu)\n",
        "    fc2w_sigma_param = softplus(pyro.param(\"fc2w_sigma\", fc2w_sigma))\n",
        "    fc2Layer_w = Normal(loc=fc2w_mu_param, scale=fc2w_sigma_param).independent(1)\n",
        "\n",
        "    # Second fully connected layer bias distribution priors\n",
        "    fc2b_mu = torch.randn_like(net.fc2.bias)\n",
        "    fc2b_sigma = torch.randn_like(net.fc2.bias)\n",
        "    fc2b_mu_param = pyro.param(\"fc2b_mu\", fc2b_mu)\n",
        "    fc2b_sigma_param = softplus(pyro.param(\"fc2b_sigma\", fc2b_sigma))\n",
        "    fc2Layer_b = Normal(loc=fc2b_mu_param, scale=fc2b_sigma_param)\n",
        "\n",
        "    # Third fully connected layer weight distribution priors\n",
        "    fc3w_mu = torch.randn_like(net.fc3.weight)\n",
        "    fc3w_sigma = torch.randn_like(net.fc3.weight)\n",
        "    fc3w_mu_param = pyro.param(\"fc3w_mu\", fc3w_mu)\n",
        "    fc3w_sigma_param = softplus(pyro.param(\"fc3w_sigma\", fc3w_sigma))\n",
        "    fc3Layer_w = Normal(loc=fc3w_mu_param, scale=fc3w_sigma_param).independent(1)\n",
        "\n",
        "    # Third fully connected layer bias distribution priors\n",
        "    fc3b_mu = torch.randn_like(net.fc3.bias)\n",
        "    fc3b_sigma = torch.randn_like(net.fc3.bias)\n",
        "    fc3b_mu_param = pyro.param(\"fc3b_mu\", fc3b_mu)\n",
        "    fc3b_sigma_param = softplus(pyro.param(\"fc3b_sigma\", fc3b_sigma))\n",
        "    fc3Layer_b = Normal(loc=fc3b_mu_param, scale=fc3b_sigma_param)\n",
        "\n",
        "    priors = {'conv1[0].weight': convLayer1_w,\n",
        "              'conv1[0].bias': convLayer1_b,\n",
        "              'conv2[0].weight': convLayer2_w,\n",
        "              'conv2[0].bias': convLayer2_b,\n",
        "              'conv3[0].weight': convLayer3_w,\n",
        "              'conv3[0].bias': convLayer3_b,\n",
        "              'conv4[0].weight': convLayer4_w,\n",
        "              'conv4[0].bias': convLayer4_b,\n",
        "              'conv5[0].weight': convLayer5_w,\n",
        "              'conv5[0].bias': convLayer5_b,\n",
        "              'fc1.weight': fc1Layer_w,\n",
        "              'fc1.bias': fc1Layer_b,\n",
        "              'fc2.weight': fc2Layer_w,\n",
        "              'fc2.bias': fc2Layer_b,\n",
        "              'fc3.weight': fc3Layer_w,\n",
        "              'fc3.bias': fc3Layer_b}\n",
        "\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "\n",
        "    return lifted_module()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO3LecLVzsux"
      },
      "source": [
        "**Training a model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uO7gpZVazwz3"
      },
      "outputs": [],
      "source": [
        "optim = Adam({'lr': 0.01})\n",
        "svi = SVI(model, guide, optim, loss=Trace_ELBO())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(val_loader, accuracy=False):\n",
        "  if accuracy:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for batch_id, data in enumerate(val_loader):\n",
        "            x_val, y_val = data[0].to(device), data[1].to(device)\n",
        "            # Get predictions from sampled models\n",
        "            yhats = [guide(None, None)(x_val) for _ in range(5)]\n",
        "            avg_yhat = torch.mean(torch.stack(yhats), dim=0)  # Average over the sampled models\n",
        "            \n",
        "            # Get predicted classes\n",
        "            _, predicted = torch.max(avg_yhat, 1)\n",
        "            total += y_val.size(0)  # Total samples\n",
        "            correct += (predicted == y_val).sum().item()  # Correct predictions\n",
        "\n",
        "    accuracy = round(correct / total *100, 2)\n",
        "    return accuracy\n",
        "  else:\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "      for batch_id, data in enumerate(val_loader):\n",
        "        x_val, y_val = data[0].to(device), data[1].to(device)\n",
        "        loss += svi.evaluate_loss(x_val, y_val)\n",
        "    normalizer_val = len(val_loader.dataset)\n",
        "    total_epoch_loss_val = loss / normalizer_val\n",
        "    return total_epoch_loss_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t2jl0MH3kow"
      },
      "outputs": [],
      "source": [
        "num_iterations = 30\n",
        "loss = 0\n",
        "losses = []\n",
        "val_performs = []\n",
        "\n",
        "for j in range(num_iterations):\n",
        "    loss = 0\n",
        "    for batch_id, data in enumerate(train_loader):\n",
        "        # calculate the loss and take a gradient step\n",
        "        loss += svi.step(data[0].to(device), data[1].to(device))\n",
        "    normalizer_train = len(train_loader.dataset)\n",
        "    total_epoch_loss_train = loss / normalizer_train\n",
        "    \n",
        "    # Get accuracy\n",
        "    with torch.no_grad():\n",
        "        net.eval()\n",
        "        val_perform = evaluate_model(val_loader, accuracy=True)\n",
        "        val_performs.append(val_perform)\n",
        "        net.train()\n",
        "\n",
        "    print(\"Epoch \", j, \" Loss \", total_epoch_loss_train, \" Validation performance: \", val_perform)\n",
        "\n",
        "# Save to file\n",
        "save_df_path = os.path.join(\"..\", \"results\", \"training_performance.csv\")\n",
        "save_data = {\"TrainingLoss\": losses, \"ValidationAccuracy\": val_performs}    \n",
        "df = pd.DataFrame(save_data)\n",
        "df.to_csv(save_df_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykaKfXV-3746"
      },
      "source": [
        "**Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW2yCU32393A"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "num_samples = 3\n",
        "def predict(x):\n",
        "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
        "    yhats = [model(x).data for model in sampled_models]\n",
        "    mean = torch.mean(torch.stack(yhats), 0)\n",
        "    return torch.argmax(mean, dim=1)\n",
        "\n",
        "print('Prediction when network is forced to predict')\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "all_labels = []\n",
        "all_predicted = []\n",
        "for j, data in enumerate(test_loader):\n",
        "    images, labels = data\n",
        "    predicted = predict(images.to(device))\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.to(device)).sum().item()\n",
        "    all_labels.append(labels)\n",
        "    all_predicted.append(predicted)\n",
        "print(\"accuracy: %d %%\" % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9zlHfh14IDz"
      },
      "source": [
        "**Save the model**\n",
        "\n",
        "First cell is using dill to store the model and parameters, if a weakref object is detected.\n",
        "I had to change the original code because pickle was not able to store the parameters due to the weakref object.\n",
        "\n",
        "The second cell is the originally provided code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Paths to folder and file for saving\n",
        "path = os.path.join(\"..\", \"results\", \"pretrained_models\")\n",
        "\n",
        "# Create folder if not already existent\n",
        "if not os.path.isdir(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "model_num = '02'\n",
        "\n",
        "torch.save({\"model\" : net.state_dict(), \"guide\" : guide}, path + \"/model_\" + model_num + \".pt\")\n",
        "\n",
        "try:\n",
        "    pyro.get_param_store().save(path + \"/model_\" + model_num + \"_params.pt\")\n",
        "\n",
        "except TypeError:\n",
        "    print(\"Weakref object was detected, using alternative way to store parameters...\")\n",
        "    # Use dill to store parameters if weakref object was detected (which causes a TypeError)\n",
        "    params = pyro.get_param_store()\n",
        "    param_keys = list(params.get_all_param_names())\n",
        "    # Create dictionary manually\n",
        "    params_workaround = {param_key: params.get_param(param_key) for param_key in param_keys}\n",
        "    # Store using dill instead of pickle (dill can handle weakref objects)\n",
        "    save_path = os.path.join(\"results\",\"pretrained_models\", \"model_\"+model_num+\"_params.pt\")\n",
        "    with open(save_path, 'wb') as file:\n",
        "        dill.dump(params_workaround, file)\n",
        "\n",
        "    print(\"\\nParameters have been stored using dill package!\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoK5Rpba4LDw"
      },
      "outputs": [],
      "source": [
        "path = 'INSERT PATH HERE'\n",
        "model_num = '01'\n",
        "torch.save({\"model\" : net.state_dict(), \"guide\" : guide}, path + \"model_\" + model_num + \".pt\")\n",
        "pyro.get_param_store().save(path + \"model_\" + model_num + \"_params.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.AlexNet import AlexNet\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First get AlexNet pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation steps for input data \n",
    "AlexTransform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3), # images need to be RGB, MNIST is in greyscale. Therefore needs to be converted to RGB\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(227),\n",
    "    transforms.ToTensor(), # Also brings the tensor values in the range [0, 1] instead of [0, 255]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Path to mnist data\n",
    "mnist_data_path = os.path.join(\"..\", \"..\", \"data\", 'mnist-data')\n",
    "\n",
    "# Create a loader for training data and testing data\n",
    "batch_size = 500\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(mnist_data_path, train=True, download=True, transform=AlexTransform),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(mnist_data_path, train=False, download=True, transform=AlexTransform),\n",
    "        batch_size=1, shuffle=False)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(mnist_data_path, train=False, download=True, transform=AlexTransform),\n",
    "        batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get AlexNet Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-trained from PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get pretrained model with default weights\n",
    "# net = models.alexnet(weights=models.AlexNet_Weights.DEFAULT)\n",
    "\n",
    "# # Change last layer to reflect MNIST categories\n",
    "# net_fc = net.classifier[-1] \n",
    "# num_ftrs = net_fc.in_features # Get the amount of input features for the last layer\n",
    "\n",
    "# # Update to 10 possible outputs\n",
    "# net.classifier[-1] = nn.Linear(num_ftrs, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-trained from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AlexNet(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load weights from trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_path = os.path.join(\"..\",\"..\",\"data\", \"AlexNet\", \"AlexNet_scratch_MNIST.pth\")\n",
    "net.load_state_dict(torch.load(net_path, weights_only=True))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction time baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output:  [[ -1.607969     0.07599767   1.8708941    2.9814165   -4.621875\n",
      "   -2.6990287  -13.791724    15.921742    -1.9459884    2.5531282 ]]\n",
      "Softmax output:  [[2.4374810e-08 1.3130408e-07 7.9030025e-07 2.3993068e-06 1.1967908e-09\n",
      "  8.1865252e-09 1.2462446e-13 9.9999511e-01 1.7383645e-08 1.5634447e-06]]\n"
     ]
    }
   ],
   "source": [
    "# Get image from test_loader\n",
    "image, label = next(iter(test_loader))\n",
    "\n",
    "# Get prediction\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_raw = net(image)\n",
    "pred_probs = softmax(pred_raw)\n",
    "print(\"Raw output: \", pred_raw.detach().numpy())\n",
    "print(\"Softmax output: \", pred_probs.detach().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

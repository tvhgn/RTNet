{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**How to run this script?**\n",
        "\n",
        "\n",
        "1.   Navigate to \"**Simulations**\" section and set the path \n",
        "where you located the Anytime Prediction models and determine where you want the output saved.\n",
        "2. You are all set! Now you can run the script on Google Colab."
      ],
      "metadata": {
        "id": "dlFh9l4QV6VS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh-PaMlF6rKT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from IPython import display\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "c7bRcIMz8M8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0664d86-4819-4ec6-c466-3086a773fed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the data**"
      ],
      "metadata": {
        "id": "c4LqCVrzWBmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500\n",
        "\n",
        "AlexTransform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=True, download=True, transform=AlexTransform),\n",
        "        batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=False, transform=AlexTransform),\n",
        "        batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "bBWVLE7ANSkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the model**"
      ],
      "metadata": {
        "id": "vHCxkSOzWIzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet\n",
        "class alexnet(nn.Module):  \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(27*27*96, 10)\n",
        "        self.fc2 = nn.Linear(13*13*256, 10)\n",
        "        self.fc3 = nn.Linear(13*13*384, 10)\n",
        "        self.fc4 = nn.Linear(13*13*384, 10)\n",
        "        self.fc5 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc6 = nn.Linear(4096, 4096)\n",
        "        self.fc7 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out1 = out.view(out.size(0), -1)\n",
        "        out1 = self.fc1(out1)\n",
        "        out1 = F.log_softmax(out1, dim=1)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out2 = out.view(out.size(0), -1)\n",
        "        out2 = self.fc2(out2)\n",
        "        out2 = F.log_softmax(out2, dim=1)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out3 = out.view(out.size(0), -1)\n",
        "        out3 = self.fc3(out3)\n",
        "        out3 = F.log_softmax(out3, dim=1)\n",
        "\n",
        "        out = self.conv4(out)\n",
        "        out4 = out.view(out.size(0), -1)\n",
        "        out4 = self.fc4(out4)\n",
        "        out4 = F.log_softmax(out4, dim=1)\n",
        "\n",
        "        out = self.conv5(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = F.relu(self.fc5(out))  # 256*6*6 -> 4096\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = F.relu(self.fc6(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = self.fc7(out)\n",
        "        out = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return out1, out2, out3, out4, out"
      ],
      "metadata": {
        "id": "uOg3ITdAiDjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer**"
      ],
      "metadata": {
        "id": "S-xayJ0lWRDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = alexnet().to(device)\n",
        "optimizer = optim.Adam(cnn.parameters())"
      ],
      "metadata": {
        "id": "rbdZ-i8bPF8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss function**"
      ],
      "metadata": {
        "id": "6SJFb-CsWVQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(out1, out2, out3, out4, out5, y):\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    loss1 = loss_func(out1, y)\n",
        "    loss2 = loss_func(out2, y)\n",
        "    loss3 = loss_func(out3, y)\n",
        "    loss4 = loss_func(out4, y)\n",
        "    loss5 = loss_func(out5, y)\n",
        "    loss = 1 * loss1 + 2 * loss2 + 3 * loss3 + 4 * loss4 + 5 * loss5\n",
        "    return loss"
      ],
      "metadata": {
        "id": "KPRjRhrMrZVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "qRfkelL8WdjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No need for the following cell if loading the pretrained models"
      ],
      "metadata": {
        "id": "TbcCo_sDWhf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(cnn, train_loader, epoch, num_epochs):\n",
        "    \n",
        "    cnn.train()\n",
        "        \n",
        "    # Train the model\n",
        "    total_step = len(train_loader)\n",
        "        \n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # gives batch data, normalize x when iterate train_loader\n",
        "        b_x = Variable(images).to(device)   # batch x\n",
        "        b_y = Variable(labels).to(device)   # batch y\n",
        "        output1, output2, output3, output4, output5 = cnn(b_x)\n",
        "        loss = compute_loss(output1, output2, output3, output4, output5, b_y)\n",
        "        optimizer.zero_grad() # clear gradients for this training step\n",
        "        loss.backward() # backpropagation, compute gradients\n",
        "        optimizer.step() # apply gradients\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, num_epochs, i + 1, total_step, loss.item()))\n",
        "\n",
        "# train(cnn, train_loader)"
      ],
      "metadata": {
        "id": "pRWOyYxYPLG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "zdgOg7T4WuF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(noise=0):\n",
        "\n",
        "    # Test the model\n",
        "    cnn.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        i = 0\n",
        "        soft_out1 = torch.zeros((10000,10))\n",
        "        soft_out2 = torch.zeros((10000,10))\n",
        "        soft_out3 = torch.zeros((10000,10))\n",
        "        soft_out4 = torch.zeros((10000,10))\n",
        "        soft_out5 = torch.zeros((10000,10))\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "            images = images + noise * torch.rand(images.shape)\n",
        "            test_output1, test_output2, test_output3, test_output4, test_output5 = cnn(images.to(device))\n",
        "            soft_out1[i*batch_size:(i+1)*batch_size,:] = test_output1\n",
        "            soft_out2[i*batch_size:(i+1)*batch_size,:] = test_output2\n",
        "            soft_out3[i*batch_size:(i+1)*batch_size,:] = test_output3\n",
        "            soft_out4[i*batch_size:(i+1)*batch_size,:] = test_output4\n",
        "            soft_out5[i*batch_size:(i+1)*batch_size,:] = test_output5\n",
        "            pred_y1 = torch.max(test_output1, 1)[1].data.squeeze()\n",
        "            pred_y2 = torch.max(test_output2, 1)[1].data.squeeze()\n",
        "            pred_y3 = torch.max(test_output3, 1)[1].data.squeeze()\n",
        "            pred_y4 = torch.max(test_output4, 1)[1].data.squeeze()\n",
        "            pred_y5 = torch.max(test_output5, 1)[1].data.squeeze()\n",
        "            accuracy1 = (pred_y1 == labels.to(device)).sum().item() / float(labels.to(device).size(0))\n",
        "            accuracy2 = (pred_y2 == labels.to(device)).sum().item() / float(labels.to(device).size(0))\n",
        "            accuracy3 = (pred_y3 == labels.to(device)).sum().item() / float(labels.to(device).size(0))\n",
        "            accuracy4 = (pred_y4 == labels.to(device)).sum().item() / float(labels.to(device).size(0))\n",
        "            accuracy5 = (pred_y5 == labels.to(device)).sum().item() / float(labels.to(device).size(0))\n",
        "\n",
        "            i = i + 1\n",
        "\n",
        "        print('Test Accuracy of the layer1 on the 10000 test images: %.2f' % accuracy1)\n",
        "        print('Test Accuracy of the layer2 on the 10000 test images: %.2f' % accuracy2)\n",
        "        print('Test Accuracy of the layer3 on the 10000 test images: %.2f' % accuracy3)\n",
        "        print('Test Accuracy of the layer4 on the 10000 test images: %.2f' % accuracy4)\n",
        "        print('Test Accuracy of the layer5 on the 10000 test images: %.2f' % accuracy5)\n",
        "\n",
        "    return soft_out1.cpu().numpy(), soft_out2.cpu().numpy(), soft_out3.cpu().numpy(), soft_out4.cpu().numpy(), soft_out5.cpu().numpy()\n"
      ],
      "metadata": {
        "id": "O_7paaHadACp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simulations**"
      ],
      "metadata": {
        "id": "YRg7bSNEW8Xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = 'LOAD_PATH'\n",
        "save_path = 'SAVE_APTH'\n",
        "noise_level = [2, 3]\n",
        "for i in range(61):\n",
        "    model_num = str(i).zfill(2)\n",
        "    cnn.load_state_dict(torch.load(load_path + '/model_' + model_num))\n",
        "    print('################### model ' + model_num + ' ###################')\n",
        "    anytime_df = pd.DataFrame(data=[])\n",
        "    for noise in noise_level:\n",
        "        out1, out2, out3, out4, out5 = np.exp(test(noise)) # converting log softmax into softmax by exp\n",
        "        out_dict = {'noise': noise,\n",
        "                    'Layer1 resp': out1.argmax(axis=1),\n",
        "                    'Layer1 conf': out1.max(axis=1),\n",
        "                    'Layer2 resp': out2.argmax(axis=1),\n",
        "                    'Layer2 conf': out2.max(axis=1),\n",
        "                    'Layer3 resp': out3.argmax(axis=1),\n",
        "                    'Layer3 conf': out3.max(axis=1),\n",
        "                    'Layer4 resp': out4.argmax(axis=1),\n",
        "                    'Layer4 conf': out4.max(axis=1),\n",
        "                    'Layer5 resp': out5.argmax(axis=1),\n",
        "                    'Layer5 conf': out5.max(axis=1)}\n",
        "        df = pd.DataFrame(data=out_dict)\n",
        "        anytime_df = anytime_df.append(df)\n",
        "\n",
        "    anytime_df = anytime_df.reset_index()\n",
        "    anytime_df.rename(columns={'index':'image_index'}, inplace=True)\n",
        "    anytime_df['image_index'] = anytime_df['image_index'] + 1\n",
        "    anytime_df.to_csv(save_path + '/anytime_prediction_' + model_num +'.csv')"
      ],
      "metadata": {
        "id": "RTpi6KpZeQIU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
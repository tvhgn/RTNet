{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlSS96RwlFrT"
      },
      "source": [
        "**How to run this script?**\n",
        "\n",
        "\n",
        "1.   Navigate to \"**Load the pretrained model**\" section and set the path\n",
        "where you located the Bayesian models.\n",
        "2.   Navigate to \"**Simulations**\" section and provide a location where you want to save the model output.\n",
        "3. You are all set! Now you can run the script on Google Colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4JAgS4o3mg5",
        "outputId": "6d85ea47-a3e3-4357-846a-004e9a21a88a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyro-ppl==0.2.1 in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl==0.2.1) (21.6.0)\n",
            "Requirement already satisfied: graphviz>=0.8 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl==0.2.1) (0.20.3)\n",
            "Requirement already satisfied: networkx>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl==0.2.1) (3.4)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl==0.2.1) (1.26.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl==0.2.1) (1.16.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl==0.2.1) (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->pyro-ppl==0.2.1) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->pyro-ppl==0.2.1) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyro-ppl==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N6jMxsF_xVp4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "#from google.colab import files\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rmEFaPL30Sh",
        "outputId": "e9165d4b-d154-45bc-f12a-afca0536e664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Check Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0DJT0xeAqXL"
      },
      "source": [
        "**Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTRmzMB4yMxj",
        "outputId": "5f32ac12-c6f6-401e-d575-3491f65701b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist-data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:02<00:00, 4563690.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting mnist-data/MNIST/raw/train-images-idx3-ubyte.gz to mnist-data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist-data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 65833.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting mnist-data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist-data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist-data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1092781.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting mnist-data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist-data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist-data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 11043784.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting mnist-data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist-data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "AlexTransform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=True, download=True, transform=AlexTransform),\n",
        "        batch_size=500, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=False, download=True, transform=AlexTransform),\n",
        "        batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyqaSFcs3Udj"
      },
      "source": [
        "**Define the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4QqsElxSF2F"
      },
      "source": [
        "AlexNet structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XNBayOSDyyn9"
      },
      "outputs": [],
      "source": [
        "# AlexNet\n",
        "class alexnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = self.fc3(out)\n",
        "        # out = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l-94O5iW367h"
      },
      "outputs": [],
      "source": [
        "# Define Hyper parameters\n",
        "img_size = 28 * 28\n",
        "hidden_layer_size = 1024\n",
        "num_classes = 10\n",
        "net = alexnet().to(device)\n",
        "# softmax\n",
        "log_softmax = nn.LogSoftmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COLZgZNISK4g"
      },
      "source": [
        "Model function for pyro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "liRRzYaD4Ejg"
      },
      "outputs": [],
      "source": [
        "def model(x_data, y_data):\n",
        "\n",
        "    convLayer1_w = Normal(loc=torch.ones_like(net.conv1[0].weight), scale=torch.ones_like(net.conv1[0].weight))\n",
        "    convLayer1_b = Normal(loc=torch.ones_like(net.conv1[0].bias), scale=torch.ones_like(net.conv1[0].bias))\n",
        "\n",
        "    convLayer2_w = Normal(loc=torch.ones_like(net.conv2[0].weight), scale=torch.ones_like(net.conv2[0].weight))\n",
        "    convLayer2_b = Normal(loc=torch.ones_like(net.conv2[0].bias), scale=torch.ones_like(net.conv2[0].bias))\n",
        "\n",
        "    convLayer3_w = Normal(loc=torch.ones_like(net.conv3[0].weight), scale=torch.ones_like(net.conv3[0].weight))\n",
        "    convLayer3_b = Normal(loc=torch.ones_like(net.conv3[0].bias), scale=torch.ones_like(net.conv3[0].bias))\n",
        "\n",
        "    convLayer4_w = Normal(loc=torch.ones_like(net.conv4[0].weight), scale=torch.ones_like(net.conv4[0].weight))\n",
        "    convLayer4_b = Normal(loc=torch.ones_like(net.conv4[0].bias), scale=torch.ones_like(net.conv4[0].bias))\n",
        "\n",
        "    convLayer5_w = Normal(loc=torch.ones_like(net.conv5[0].weight), scale=torch.ones_like(net.conv5[0].weight))\n",
        "    convLayer5_b = Normal(loc=torch.ones_like(net.conv5[0].bias), scale=torch.ones_like(net.conv5[0].bias))\n",
        "\n",
        "    fc1Layer_w = Normal(loc=torch.ones_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
        "    fc1Layer_b = Normal(loc=torch.ones_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
        "\n",
        "    fc2Layer_w = Normal(loc=torch.ones_like(net.fc2.weight), scale=torch.ones_like(net.fc2.weight))\n",
        "    fc2Layer_b = Normal(loc=torch.ones_like(net.fc2.bias), scale=torch.ones_like(net.fc2.bias))\n",
        "\n",
        "    fc3Layer_w = Normal(loc=torch.ones_like(net.fc3.weight), scale=torch.ones_like(net.fc3.weight))\n",
        "    fc3Layer_b = Normal(loc=torch.ones_like(net.fc3.bias), scale=torch.ones_like(net.fc3.bias))\n",
        "\n",
        "    priors = {'conv1[0].weight': convLayer1_w,\n",
        "              'conv1[0].bias': convLayer1_b,\n",
        "              'conv2[0].weight': convLayer2_w,\n",
        "              'conv2[0].bias': convLayer2_b,\n",
        "              'conv3[0].weight': convLayer3_w,\n",
        "              'conv3[0].bias': convLayer3_b,\n",
        "              'conv4[0].weight': convLayer4_w,\n",
        "              'conv4[0].bias': convLayer4_b,\n",
        "              'conv5[0].weight': convLayer5_w,\n",
        "              'conv5[0].bias': convLayer5_b,\n",
        "              'fc1.weight': fc1Layer_w,\n",
        "              'fc1.bias': fc1Layer_b,\n",
        "              'fc2.weight': fc2Layer_w,\n",
        "              'fc2.bias': fc2Layer_b,\n",
        "              'fc3.weight': fc3Layer_w,\n",
        "              'fc3.bias': fc3Layer_b}\n",
        "\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    # sample a regressor (which also samples w and b)\n",
        "    lifted_reg_model = lifted_module()\n",
        "\n",
        "    lhat = log_softmax(lifted_reg_model(x_data))\n",
        "\n",
        "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4OnUndST19"
      },
      "source": [
        "Guide function for pyro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "So18-_z_4Hv3"
      },
      "outputs": [],
      "source": [
        "softplus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "\n",
        "    # First layer weight distribution priors\n",
        "    convLayer1w_mu    = torch.randn_like(net.conv1[0].weight)\n",
        "    convLayer1w_sigma = torch.randn_like(net.conv1[0].weight)\n",
        "    convLayer1w_mu_param    = pyro.param(\"convLayer1w_mu\", convLayer1w_mu)\n",
        "    convLayer1w_sigma_param = softplus(pyro.param(\"convLayer1w_sigma\", convLayer1w_sigma))\n",
        "    convLayer1_w = Normal(loc=convLayer1w_mu_param, scale=convLayer1w_sigma_param)\n",
        "\n",
        "    # First layer bias distribution priors\n",
        "    convLayer1b_mu    = torch.randn_like(net.conv1[0].bias)\n",
        "    convLayer1b_sigma = torch.randn_like(net.conv1[0].bias)\n",
        "    convLayer1b_mu_param    = pyro.param(\"convLayer1b_mu\", convLayer1b_mu)\n",
        "    convLayer1b_sigma_param = softplus(pyro.param(\"convLayer1b_sigma\", convLayer1b_sigma))\n",
        "    convLayer1_b = Normal(loc=convLayer1b_mu_param, scale=convLayer1b_sigma_param)\n",
        "\n",
        "    # Second layer weight distribution priors\n",
        "    convLayer2w_mu    = torch.randn_like(net.conv2[0].weight)\n",
        "    convLayer2w_sigma = torch.randn_like(net.conv2[0].weight)\n",
        "    convLayer2w_mu_param    = pyro.param(\"convLayer2w_mu\", convLayer2w_mu)\n",
        "    convLayer2w_sigma_param = softplus(pyro.param(\"convLayer2w_sigma\", convLayer2w_sigma))\n",
        "    convLayer2_w = Normal(loc=convLayer2w_mu_param, scale=convLayer2w_sigma_param)\n",
        "\n",
        "    # Second layer bias distribution priors\n",
        "    convLayer2b_mu    = torch.randn_like(net.conv2[0].bias)\n",
        "    convLayer2b_sigma = torch.randn_like(net.conv2[0].bias)\n",
        "    convLayer2b_mu_param    = pyro.param(\"convLayer2b_mu\", convLayer2b_mu)\n",
        "    convLayer2b_sigma_param = softplus(pyro.param(\"convLayer2b_sigma\", convLayer2b_sigma))\n",
        "    convLayer2_b = Normal(loc=convLayer2b_mu_param, scale=convLayer2b_sigma_param)\n",
        "\n",
        "    # Third layer weight distribution priors\n",
        "    convLayer3w_mu    = torch.randn_like(net.conv3[0].weight)\n",
        "    convLayer3w_sigma = torch.randn_like(net.conv3[0].weight)\n",
        "    convLayer3w_mu_param    = pyro.param(\"convLayer3w_mu\", convLayer3w_mu)\n",
        "    convLayer3w_sigma_param = softplus(pyro.param(\"convLayer3w_sigma\", convLayer3w_sigma))\n",
        "    convLayer3_w = Normal(loc=convLayer3w_mu_param, scale=convLayer3w_sigma_param)\n",
        "\n",
        "    # Third layer bias distribution priors\n",
        "    convLayer3b_mu    = torch.randn_like(net.conv3[0].bias)\n",
        "    convLayer3b_sigma = torch.randn_like(net.conv3[0].bias)\n",
        "    convLayer3b_mu_param    = pyro.param(\"convLayer3b_mu\", convLayer3b_mu)\n",
        "    convLayer3b_sigma_param = softplus(pyro.param(\"convLayer3b_sigma\", convLayer3b_sigma))\n",
        "    convLayer3_b = Normal(loc=convLayer3b_mu_param, scale=convLayer3b_sigma_param)\n",
        "\n",
        "    # Fourth layer weight distribution priors\n",
        "    convLayer4w_mu    = torch.randn_like(net.conv4[0].weight)\n",
        "    convLayer4w_sigma = torch.randn_like(net.conv4[0].weight)\n",
        "    convLayer4w_mu_param    = pyro.param(\"convLayer4w_mu\", convLayer4w_mu)\n",
        "    convLayer4w_sigma_param = softplus(pyro.param(\"convLayer4w_sigma\", convLayer4w_sigma))\n",
        "    convLayer4_w = Normal(loc=convLayer4w_mu_param, scale=convLayer4w_sigma_param)\n",
        "\n",
        "    # Fourth layer bias distribution priors\n",
        "    convLayer4b_mu    = torch.randn_like(net.conv4[0].bias)\n",
        "    convLayer4b_sigma = torch.randn_like(net.conv4[0].bias)\n",
        "    convLayer4b_mu_param    = pyro.param(\"convLayer4b_mu\", convLayer4b_mu)\n",
        "    convLayer4b_sigma_param = softplus(pyro.param(\"convLayer4b_sigma\", convLayer4b_sigma))\n",
        "    convLayer4_b = Normal(loc=convLayer4b_mu_param, scale=convLayer4b_sigma_param)\n",
        "\n",
        "    # Fifth layer weight distribution priors\n",
        "    convLayer5w_mu    = torch.randn_like(net.conv5[0].weight)\n",
        "    convLayer5w_sigma = torch.randn_like(net.conv5[0].weight)\n",
        "    convLayer5w_mu_param    = pyro.param(\"convLayer5w_mu\", convLayer5w_mu)\n",
        "    convLayer5w_sigma_param = softplus(pyro.param(\"convLayer5w_sigma\", convLayer5w_sigma))\n",
        "    convLayer5_w = Normal(loc=convLayer5w_mu_param, scale=convLayer5w_sigma_param)\n",
        "\n",
        "    # Fifth layer bias distribution priors\n",
        "    convLayer5b_mu    = torch.randn_like(net.conv5[0].bias)\n",
        "    convLayer5b_sigma = torch.randn_like(net.conv5[0].bias)\n",
        "    convLayer5b_mu_param    = pyro.param(\"convLayer5b_mu\", convLayer5b_mu)\n",
        "    convLayer5b_sigma_param = softplus(pyro.param(\"convLayer5b_sigma\", convLayer5b_sigma))\n",
        "    convLayer5_b = Normal(loc=convLayer5b_mu_param, scale=convLayer5b_sigma_param)\n",
        "\n",
        "    # First fully connected layer weight distribution priors\n",
        "    fc1w_mu = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
        "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
        "    fc1Layer_w = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param).independent(1)\n",
        "\n",
        "    # First fully connected layer bias distribution priors\n",
        "    fc1b_mu = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
        "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
        "    fc1Layer_b = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
        "\n",
        "    # Second fully connected layer weight distribution priors\n",
        "    fc2w_mu = torch.randn_like(net.fc2.weight)\n",
        "    fc2w_sigma = torch.randn_like(net.fc2.weight)\n",
        "    fc2w_mu_param = pyro.param(\"fc2w_mu\", fc2w_mu)\n",
        "    fc2w_sigma_param = softplus(pyro.param(\"fc2w_sigma\", fc2w_sigma))\n",
        "    fc2Layer_w = Normal(loc=fc2w_mu_param, scale=fc2w_sigma_param).independent(1)\n",
        "\n",
        "    # Second fully connected layer bias distribution priors\n",
        "    fc2b_mu = torch.randn_like(net.fc2.bias)\n",
        "    fc2b_sigma = torch.randn_like(net.fc2.bias)\n",
        "    fc2b_mu_param = pyro.param(\"fc2b_mu\", fc2b_mu)\n",
        "    fc2b_sigma_param = softplus(pyro.param(\"fc2b_sigma\", fc2b_sigma))\n",
        "    fc2Layer_b = Normal(loc=fc2b_mu_param, scale=fc2b_sigma_param)\n",
        "\n",
        "    # Third fully connected layer weight distribution priors\n",
        "    fc3w_mu = torch.randn_like(net.fc3.weight)\n",
        "    fc3w_sigma = torch.randn_like(net.fc3.weight)\n",
        "    fc3w_mu_param = pyro.param(\"fc3w_mu\", fc3w_mu)\n",
        "    fc3w_sigma_param = softplus(pyro.param(\"fc3w_sigma\", fc3w_sigma))\n",
        "    fc3Layer_w = Normal(loc=fc3w_mu_param, scale=fc3w_sigma_param).independent(1)\n",
        "\n",
        "    # Third fully connected layer bias distribution priors\n",
        "    fc3b_mu = torch.randn_like(net.fc3.bias)\n",
        "    fc3b_sigma = torch.randn_like(net.fc3.bias)\n",
        "    fc3b_mu_param = pyro.param(\"fc3b_mu\", fc3b_mu)\n",
        "    fc3b_sigma_param = softplus(pyro.param(\"fc3b_sigma\", fc3b_sigma))\n",
        "    fc3Layer_b = Normal(loc=fc3b_mu_param, scale=fc3b_sigma_param)\n",
        "\n",
        "    priors = {'conv1[0].weight': convLayer1_w,\n",
        "              'conv1[0].bias': convLayer1_b,\n",
        "              'conv2[0].weight': convLayer2_w,\n",
        "              'conv2[0].bias': convLayer2_b,\n",
        "              'conv3[0].weight': convLayer3_w,\n",
        "              'conv3[0].bias': convLayer3_b,\n",
        "              'conv4[0].weight': convLayer4_w,\n",
        "              'conv4[0].bias': convLayer4_b,\n",
        "              'conv5[0].weight': convLayer5_w,\n",
        "              'conv5[0].bias': convLayer5_b,\n",
        "              'fc1.weight': fc1Layer_w,\n",
        "              'fc1.bias': fc1Layer_b,\n",
        "              'fc2.weight': fc2Layer_w,\n",
        "              'fc2.bias': fc2Layer_b,\n",
        "              'fc3.weight': fc3Layer_w,\n",
        "              'fc3.bias': fc3Layer_b}\n",
        "\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "\n",
        "    return lifted_module()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkWj6hP7m5Wb"
      },
      "source": [
        "**Load the pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjXvlXSz4KXG",
        "outputId": "41d8d03c-e88c-4005-deda-c01322987b14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-163b3b3872fd>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  saved_model_dict = torch.load(model_path + 'model_01.pt') # model #1 in the path\n",
            "/usr/local/lib/python3.10/dist-packages/pyro/params/param_store.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(input_file)\n"
          ]
        }
      ],
      "source": [
        "model_path = 'Bayesian_models/' # This should be the path where the models are located\n",
        "saved_model_dict = torch.load(model_path + 'model_01.pt') # model #1 in the path\n",
        "net.load_state_dict(saved_model_dict['model'])\n",
        "guide = saved_model_dict['guide']\n",
        "pyro.get_param_store().load(model_path + \"model_01_params.pt\") # model #1 in the path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcMyqXVQR7l2"
      },
      "source": [
        "**Define utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "04cayGzoe4zC"
      },
      "outputs": [],
      "source": [
        "def give_uncertainities(x, num_samples=1):\n",
        "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
        "    yhats = [F.log_softmax(model(x).data, dim=1) for model in sampled_models]\n",
        "    return yhats[0]\n",
        "\n",
        "def compute_evidence(image):\n",
        "    # image = image.unsqueeze(dim=0)\n",
        "    y = give_uncertainities(image)\n",
        "    return y\n",
        "\n",
        "def compute_confidence(evidence):\n",
        "    conf = torch.exp(evidence)\n",
        "    conf = conf / torch.sum(conf)\n",
        "    conf_diff = conf.sort().values[0][-1] - conf.sort().values[0][-2]\n",
        "    return conf_diff, conf\n",
        "\n",
        "\n",
        "def decide(image, threshold=10):\n",
        "    rt = 0\n",
        "    max_evidence, total_evidence = 0, 0\n",
        "    while max_evidence < threshold:\n",
        "      evidence = torch.exp(compute_evidence(image))\n",
        "      total_evidence = total_evidence + evidence\n",
        "      max_evidence = torch.max(total_evidence)\n",
        "      rt = rt + 1\n",
        "    choice = torch.argmax(total_evidence)\n",
        "    confidence, confidence_array = compute_confidence(total_evidence)\n",
        "    return int(choice.cpu().numpy()), rt, float(confidence.cpu().numpy()), confidence_array.cpu().numpy()\n",
        "\n",
        "def save_df(index, Choice, RT, Confidence, Threshold, Noise, Labels, image_stats, path):\n",
        "    # unpack image data\n",
        "    noise_max, noise_mean, image_max, image_mean, noisy_image_max, noisy_image_mean = image_stats\n",
        "\n",
        "    simulations = {'mnist_index': index,\n",
        "                   'choice': Choice,\n",
        "                   'rt': RT,\n",
        "                   'confidence': Confidence,\n",
        "                   'threshold': Threshold,\n",
        "                   'noise': Noise,\n",
        "                   'true label': Labels,\n",
        "                   'noise max': noise_max,\n",
        "                   'noise mean': noise_mean,\n",
        "                   'image max': image_max,\n",
        "                   'image mean': image_mean,\n",
        "                   'noisy_image max': noisy_image_max,\n",
        "                   'noisy_image mean': noisy_image_mean}\n",
        "\n",
        "    df = pd.DataFrame(simulations)\n",
        "    df.to_csv(path)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlYwlVoYAWQn"
      },
      "source": [
        "**Simulations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u7XgcKC4res",
        "outputId": "dba6c64a-99d0-448a-da8c-652bdf2dd527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set the threshold to 5\n",
            "   Set the evidence level to 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-b10b34aec182>:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  all_labels.append(int(label.cpu().numpy()))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the evidence level to 0.3\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the evidence level to 0.4\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the evidence level to 0.5\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the evidence level to 0.6\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the evidence level to 0.7\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n"
          ]
        }
      ],
      "source": [
        "threshold_levels = [5]\n",
        "\n",
        "save_path = 'results/noise_level_sims.csv' # path to where you want to save the output\n",
        "all_index, all_choice, all_rt, all_confidence, all_threshold, all_labels, all_ev = [], [], [], [], [], [], []\n",
        "\n",
        "# image statistics lists\n",
        "noise_max, noise_mean, image_max, image_mean, noisy_image_max, noisy_image_mean = [], [], [], [], [], []\n",
        "\n",
        "# Iterate across threshold levels.\n",
        "for a in threshold_levels:\n",
        "  print(\"Set the threshold to {}\".format(str(a)))\n",
        "  # Iterate across levels of evidence strength (ef=evidence factor). 0 = pure noise, 1 = pure evidence\n",
        "  for ev in np.arange(0.2, 1.1, 0.1).round(1):\n",
        "      # Set save_path\n",
        "      save_path = 'results/evidence_level_sims_' + str(a) + \"_\" + str(ev).replace(\".\", \"_\") + \".csv\"\n",
        "      print('   Set the evidence level to {}'.format(str(ev)))\n",
        "      for i, (image, label) in enumerate(test_loader):\n",
        "        # Compute final image as a weighted blend between pure noise and the original image\n",
        "        # Compute noise array\n",
        "        noise_array = torch.rand(image.shape) * image.max() # multiply with the max value to make the noise as strong as the original image.\n",
        "        # Compute final image\n",
        "        noisy_image = ev*image + (1-ev)*noise_array\n",
        "        # Get data\n",
        "        choice, rt, confidence, _ = decide(noisy_image.to(device), threshold=a)\n",
        "        all_index.append(i)\n",
        "        all_choice.append(choice)\n",
        "        all_rt.append(rt)\n",
        "        all_confidence.append(confidence)\n",
        "        all_threshold.append(a)\n",
        "        all_ev.append(ev)\n",
        "        all_labels.append(int(label.cpu().numpy()))\n",
        "\n",
        "        # image and noise data\n",
        "        noise_max.append(noise_array.max().cpu().numpy())\n",
        "        noise_mean.append(noise_array.mean().cpu().numpy())\n",
        "        image_max.append(image[image>0].max().cpu().numpy()) # Just take the positive non-zero values (the actual pixels belonging to the evidence)\n",
        "        image_mean.append(image[image>0].mean().cpu().numpy())\n",
        "        noisy_image_max.append(noisy_image.max().cpu().numpy())\n",
        "        noisy_image_mean.append(noisy_image.mean().cpu().numpy())\n",
        "\n",
        "        # Print progress after each 1000 images.\n",
        "        if (i%1000)==0:\n",
        "          print('           {}'.format(str(i)))\n",
        "\n",
        "      # store image stats in single list\n",
        "      all_image_stats = [noise_max, noise_mean, image_max, image_mean, noisy_image_max, noisy_image_mean]\n",
        "      # Save to file.\n",
        "      save_df(all_index, all_choice, all_rt, all_confidence, all_threshold, all_ev, all_labels, all_image_stats, save_path)\n",
        "      # Automatically download to local drive\n",
        "      #files.download(save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E9lYY5qphf9"
      },
      "source": [
        "**Example Images with Noise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "FnbyZldWpgnI",
        "outputId": "7e22d41f-ac1a-4112-9e91-b45de98873f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'results/evidence_level_sims_5_0_1.csv'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = 5\n",
        "ev = 0.1\n",
        "save_path = 'results/evidence_level_sims_' + str(a) + \"_\" + str(ev).replace(\".\", \"_\") + \".csv\"\n",
        "\n",
        "save_path"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

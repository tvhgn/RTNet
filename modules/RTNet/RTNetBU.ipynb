{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlSS96RwlFrT"
      },
      "source": [
        "**How to run this script?**\n",
        "\n",
        "\n",
        "1.   Navigate to \"**Load the pretrained model**\" section and set the path \n",
        "where you located the Bayesian models. \n",
        "2.   Navigate to \"**Simulations**\" section and provide a location where you want to save the model output. \n",
        "3. You are all set! Now you can run the script on Google Colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H4JAgS4o3mg5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyro-ppl==0.2.1 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (0.2.1)\n",
            "Requirement already satisfied: contextlib2 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (21.6.0)\n",
            "Requirement already satisfied: graphviz>=0.8 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (0.20.3)\n",
            "Requirement already satisfied: networkx>=2.0.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (3.1)\n",
            "Requirement already satisfied: numpy>=1.7 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (1.24.4)\n",
            "Requirement already satisfied: six>=1.10.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (1.16.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from pyro-ppl==0.2.1) (2.4.0+cu124)\n",
            "Requirement already satisfied: fsspec in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (3.1.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from torch>=0.4.0->pyro-ppl==0.2.1) (1.13.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from jinja2->torch>=0.4.0->pyro-ppl==0.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\lib\\site-packages (from sympy->torch>=0.4.0->pyro-ppl==0.2.1) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.1.1; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\tomva\\onedrive\\ku leuven\\master theory and research\\internship\\rtnet\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyro-ppl==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N6jMxsF_xVp4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rmEFaPL30Sh",
        "outputId": "be7edb3c-4c64-4210-e816-ac01fe32769a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Check Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0DJT0xeAqXL"
      },
      "source": [
        "**Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tTRmzMB4yMxj"
      },
      "outputs": [],
      "source": [
        "AlexTransform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(os.path.join(\"..\", \"data\",'mnist-data'), train=True, download=True, transform=AlexTransform),\n",
        "        batch_size=500, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST(os.path.join(\"..\", \"data\",'mnist-data'), train=False, download=True, transform=AlexTransform),\n",
        "        batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyqaSFcs3Udj"
      },
      "source": [
        "**Devine the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4QqsElxSF2F"
      },
      "source": [
        "AlexNet structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XNBayOSDyyn9"
      },
      "outputs": [],
      "source": [
        "# AlexNet\n",
        "class alexnet(nn.Module):  \n",
        "    dev __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, 3, 1, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    dev forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = self.fc3(out)\n",
        "        # out = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l-94O5iW367h"
      },
      "outputs": [],
      "source": [
        "# Devine Hyper parameters\n",
        "img_size = 28 * 28\n",
        "hidden_layer_size = 1024\n",
        "num_classes = 10\n",
        "net = alexnet().to(device)\n",
        "# softmax\n",
        "log_softmax = nn.LogSoftmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COLZgZNISK4g"
      },
      "source": [
        "Model function for pyro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "liRRzYaD4Ejg"
      },
      "outputs": [],
      "source": [
        "def model(x_data, y_data):\n",
        "\n",
        "    convLayer1_w = Normal(loc=torch.ones_like(net.conv1[0].weight), scale=torch.ones_like(net.conv1[0].weight))\n",
        "    convLayer1_b = Normal(loc=torch.ones_like(net.conv1[0].bias), scale=torch.ones_like(net.conv1[0].bias))\n",
        "\n",
        "    convLayer2_w = Normal(loc=torch.ones_like(net.conv2[0].weight), scale=torch.ones_like(net.conv2[0].weight))\n",
        "    convLayer2_b = Normal(loc=torch.ones_like(net.conv2[0].bias), scale=torch.ones_like(net.conv2[0].bias))\n",
        "\n",
        "    convLayer3_w = Normal(loc=torch.ones_like(net.conv3[0].weight), scale=torch.ones_like(net.conv3[0].weight))\n",
        "    convLayer3_b = Normal(loc=torch.ones_like(net.conv3[0].bias), scale=torch.ones_like(net.conv3[0].bias))\n",
        "\n",
        "    convLayer4_w = Normal(loc=torch.ones_like(net.conv4[0].weight), scale=torch.ones_like(net.conv4[0].weight))\n",
        "    convLayer4_b = Normal(loc=torch.ones_like(net.conv4[0].bias), scale=torch.ones_like(net.conv4[0].bias))\n",
        "\n",
        "    convLayer5_w = Normal(loc=torch.ones_like(net.conv5[0].weight), scale=torch.ones_like(net.conv5[0].weight))\n",
        "    convLayer5_b = Normal(loc=torch.ones_like(net.conv5[0].bias), scale=torch.ones_like(net.conv5[0].bias))\n",
        "\n",
        "    fc1Layer_w = Normal(loc=torch.ones_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
        "    fc1Layer_b = Normal(loc=torch.ones_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
        "\n",
        "    fc2Layer_w = Normal(loc=torch.ones_like(net.fc2.weight), scale=torch.ones_like(net.fc2.weight))\n",
        "    fc2Layer_b = Normal(loc=torch.ones_like(net.fc2.bias), scale=torch.ones_like(net.fc2.bias))\n",
        "\n",
        "    fc3Layer_w = Normal(loc=torch.ones_like(net.fc3.weight), scale=torch.ones_like(net.fc3.weight))\n",
        "    fc3Layer_b = Normal(loc=torch.ones_like(net.fc3.bias), scale=torch.ones_like(net.fc3.bias))\n",
        "\n",
        "    priors = {'conv1[0].weight': convLayer1_w, \n",
        "              'conv1[0].bias': convLayer1_b,\n",
        "              'conv2[0].weight': convLayer2_w,\n",
        "              'conv2[0].bias': convLayer2_b,\n",
        "              'conv3[0].weight': convLayer3_w,\n",
        "              'conv3[0].bias': convLayer3_b,\n",
        "              'conv4[0].weight': convLayer4_w,\n",
        "              'conv4[0].bias': convLayer4_b,\n",
        "              'conv5[0].weight': convLayer5_w,\n",
        "              'conv5[0].bias': convLayer5_b,\n",
        "              'fc1.weight': fc1Layer_w, \n",
        "              'fc1.bias': fc1Layer_b,\n",
        "              'fc2.weight': fc2Layer_w, \n",
        "              'fc2.bias': fc2Layer_b,\n",
        "              'fc3.weight': fc3Layer_w, \n",
        "              'fc3.bias': fc3Layer_b}\n",
        "\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    # sample a regressor (which also samples w and b)\n",
        "    lifted_reg_model = lifted_module()\n",
        "\n",
        "    lhat = log_softmax(lifted_reg_model(x_data))\n",
        "\n",
        "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4OnUndST19"
      },
      "source": [
        "Guide function for pyro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "So18-_z_4Hv3"
      },
      "outputs": [],
      "source": [
        "softplus = torch.nn.Softplus()\n",
        "\n",
        "def guide(x_data, y_data):\n",
        "    \n",
        "    # First layer weight distribution priors\n",
        "    convLayer1w_mu    = torch.randn_like(net.conv1[0].weight)\n",
        "    convLayer1w_sigma = torch.randn_like(net.conv1[0].weight)\n",
        "    convLayer1w_mu_param    = pyro.param(\"convLayer1w_mu\", convLayer1w_mu)\n",
        "    convLayer1w_sigma_param = softplus(pyro.param(\"convLayer1w_sigma\", convLayer1w_sigma))\n",
        "    convLayer1_w = Normal(loc=convLayer1w_mu_param, scale=convLayer1w_sigma_param)\n",
        "\n",
        "    # First layer bias distribution priors\n",
        "    convLayer1b_mu    = torch.randn_like(net.conv1[0].bias)\n",
        "    convLayer1b_sigma = torch.randn_like(net.conv1[0].bias)\n",
        "    convLayer1b_mu_param    = pyro.param(\"convLayer1b_mu\", convLayer1b_mu)\n",
        "    convLayer1b_sigma_param = softplus(pyro.param(\"convLayer1b_sigma\", convLayer1b_sigma))\n",
        "    convLayer1_b = Normal(loc=convLayer1b_mu_param, scale=convLayer1b_sigma_param)\n",
        "\n",
        "    # Second layer weight distribution priors\n",
        "    convLayer2w_mu    = torch.randn_like(net.conv2[0].weight)\n",
        "    convLayer2w_sigma = torch.randn_like(net.conv2[0].weight)\n",
        "    convLayer2w_mu_param    = pyro.param(\"convLayer2w_mu\", convLayer2w_mu)\n",
        "    convLayer2w_sigma_param = softplus(pyro.param(\"convLayer2w_sigma\", convLayer2w_sigma))\n",
        "    convLayer2_w = Normal(loc=convLayer2w_mu_param, scale=convLayer2w_sigma_param)\n",
        "\n",
        "    # Second layer bias distribution priors\n",
        "    convLayer2b_mu    = torch.randn_like(net.conv2[0].bias)\n",
        "    convLayer2b_sigma = torch.randn_like(net.conv2[0].bias)\n",
        "    convLayer2b_mu_param    = pyro.param(\"convLayer2b_mu\", convLayer2b_mu)\n",
        "    convLayer2b_sigma_param = softplus(pyro.param(\"convLayer2b_sigma\", convLayer2b_sigma))\n",
        "    convLayer2_b = Normal(loc=convLayer2b_mu_param, scale=convLayer2b_sigma_param)\n",
        "\n",
        "    # Third layer weight distribution priors\n",
        "    convLayer3w_mu    = torch.randn_like(net.conv3[0].weight)\n",
        "    convLayer3w_sigma = torch.randn_like(net.conv3[0].weight)\n",
        "    convLayer3w_mu_param    = pyro.param(\"convLayer3w_mu\", convLayer3w_mu)\n",
        "    convLayer3w_sigma_param = softplus(pyro.param(\"convLayer3w_sigma\", convLayer3w_sigma))\n",
        "    convLayer3_w = Normal(loc=convLayer3w_mu_param, scale=convLayer3w_sigma_param)\n",
        "\n",
        "    # Third layer bias distribution priors\n",
        "    convLayer3b_mu    = torch.randn_like(net.conv3[0].bias)\n",
        "    convLayer3b_sigma = torch.randn_like(net.conv3[0].bias)\n",
        "    convLayer3b_mu_param    = pyro.param(\"convLayer3b_mu\", convLayer3b_mu)\n",
        "    convLayer3b_sigma_param = softplus(pyro.param(\"convLayer3b_sigma\", convLayer3b_sigma))\n",
        "    convLayer3_b = Normal(loc=convLayer3b_mu_param, scale=convLayer3b_sigma_param)\n",
        "\n",
        "    # Fourth layer weight distribution priors\n",
        "    convLayer4w_mu    = torch.randn_like(net.conv4[0].weight)\n",
        "    convLayer4w_sigma = torch.randn_like(net.conv4[0].weight)\n",
        "    convLayer4w_mu_param    = pyro.param(\"convLayer4w_mu\", convLayer4w_mu)\n",
        "    convLayer4w_sigma_param = softplus(pyro.param(\"convLayer4w_sigma\", convLayer4w_sigma))\n",
        "    convLayer4_w = Normal(loc=convLayer4w_mu_param, scale=convLayer4w_sigma_param)\n",
        "\n",
        "    # Fourth layer bias distribution priors\n",
        "    convLayer4b_mu    = torch.randn_like(net.conv4[0].bias)\n",
        "    convLayer4b_sigma = torch.randn_like(net.conv4[0].bias)\n",
        "    convLayer4b_mu_param    = pyro.param(\"convLayer4b_mu\", convLayer4b_mu)\n",
        "    convLayer4b_sigma_param = softplus(pyro.param(\"convLayer4b_sigma\", convLayer4b_sigma))\n",
        "    convLayer4_b = Normal(loc=convLayer4b_mu_param, scale=convLayer4b_sigma_param)\n",
        "\n",
        "    # Fifth layer weight distribution priors\n",
        "    convLayer5w_mu    = torch.randn_like(net.conv5[0].weight)\n",
        "    convLayer5w_sigma = torch.randn_like(net.conv5[0].weight)\n",
        "    convLayer5w_mu_param    = pyro.param(\"convLayer5w_mu\", convLayer5w_mu)\n",
        "    convLayer5w_sigma_param = softplus(pyro.param(\"convLayer5w_sigma\", convLayer5w_sigma))\n",
        "    convLayer5_w = Normal(loc=convLayer5w_mu_param, scale=convLayer5w_sigma_param)\n",
        "\n",
        "    # Fifth layer bias distribution priors\n",
        "    convLayer5b_mu    = torch.randn_like(net.conv5[0].bias)\n",
        "    convLayer5b_sigma = torch.randn_like(net.conv5[0].bias)\n",
        "    convLayer5b_mu_param    = pyro.param(\"convLayer5b_mu\", convLayer5b_mu)\n",
        "    convLayer5b_sigma_param = softplus(pyro.param(\"convLayer5b_sigma\", convLayer5b_sigma))\n",
        "    convLayer5_b = Normal(loc=convLayer5b_mu_param, scale=convLayer5b_sigma_param)\n",
        "\n",
        "    # First fully connected layer weight distribution priors\n",
        "    fc1w_mu = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
        "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
        "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
        "    fc1Layer_w = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param).independent(1)\n",
        "\n",
        "    # First fully connected layer bias distribution priors\n",
        "    fc1b_mu = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
        "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
        "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
        "    fc1Layer_b = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
        "\n",
        "    # Second fully connected layer weight distribution priors\n",
        "    fc2w_mu = torch.randn_like(net.fc2.weight)\n",
        "    fc2w_sigma = torch.randn_like(net.fc2.weight)\n",
        "    fc2w_mu_param = pyro.param(\"fc2w_mu\", fc2w_mu)\n",
        "    fc2w_sigma_param = softplus(pyro.param(\"fc2w_sigma\", fc2w_sigma))\n",
        "    fc2Layer_w = Normal(loc=fc2w_mu_param, scale=fc2w_sigma_param).independent(1)\n",
        "\n",
        "    # Second fully connected layer bias distribution priors\n",
        "    fc2b_mu = torch.randn_like(net.fc2.bias)\n",
        "    fc2b_sigma = torch.randn_like(net.fc2.bias)\n",
        "    fc2b_mu_param = pyro.param(\"fc2b_mu\", fc2b_mu)\n",
        "    fc2b_sigma_param = softplus(pyro.param(\"fc2b_sigma\", fc2b_sigma))\n",
        "    fc2Layer_b = Normal(loc=fc2b_mu_param, scale=fc2b_sigma_param)\n",
        "\n",
        "    # Third fully connected layer weight distribution priors\n",
        "    fc3w_mu = torch.randn_like(net.fc3.weight)\n",
        "    fc3w_sigma = torch.randn_like(net.fc3.weight)\n",
        "    fc3w_mu_param = pyro.param(\"fc3w_mu\", fc3w_mu)\n",
        "    fc3w_sigma_param = softplus(pyro.param(\"fc3w_sigma\", fc3w_sigma))\n",
        "    fc3Layer_w = Normal(loc=fc3w_mu_param, scale=fc3w_sigma_param).independent(1)\n",
        "\n",
        "    # Third fully connected layer bias distribution priors\n",
        "    fc3b_mu = torch.randn_like(net.fc3.bias)\n",
        "    fc3b_sigma = torch.randn_like(net.fc3.bias)\n",
        "    fc3b_mu_param = pyro.param(\"fc3b_mu\", fc3b_mu)\n",
        "    fc3b_sigma_param = softplus(pyro.param(\"fc3b_sigma\", fc3b_sigma))\n",
        "    fc3Layer_b = Normal(loc=fc3b_mu_param, scale=fc3b_sigma_param)\n",
        "\n",
        "    priors = {'conv1[0].weight': convLayer1_w, \n",
        "              'conv1[0].bias': convLayer1_b,\n",
        "              'conv2[0].weight': convLayer2_w,\n",
        "              'conv2[0].bias': convLayer2_b,\n",
        "              'conv3[0].weight': convLayer3_w,\n",
        "              'conv3[0].bias': convLayer3_b,\n",
        "              'conv4[0].weight': convLayer4_w,\n",
        "              'conv4[0].bias': convLayer4_b,\n",
        "              'conv5[0].weight': convLayer5_w,\n",
        "              'conv5[0].bias': convLayer5_b,\n",
        "              'fc1.weight': fc1Layer_w, \n",
        "              'fc1.bias': fc1Layer_b,\n",
        "              'fc2.weight': fc2Layer_w, \n",
        "              'fc2.bias': fc2Layer_b,\n",
        "              'fc3.weight': fc3Layer_w, \n",
        "              'fc3.bias': fc3Layer_b}\n",
        "\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    \n",
        "    return lifted_module()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkWj6hP7m5Wb"
      },
      "source": [
        "**Load the pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SjXvlXSz4KXG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\tomva\\AppData\\Local\\Temp\\ipykernel_13104\\3762706408.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  saved_model_dict = torch.load(model_path + '\\model_01.pt') # model #1 in the path\n",
            "c:\\Users\\tomva\\OneDrive\\KU Leuven\\Master Theory and Research\\Internship\\RTNet\\venv\\lib\\site-packages\\pyro\\params\\param_store.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(input_file)\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(\"..\", \"data\", \"Bayesian_models\") # This should be the path where the models are located\n",
        "saved_model_dict = torch.load(model_path + '\\model_01.pt') # model #1 in the path\n",
        "net.load_state_dict(saved_model_dict['model'])\n",
        "guide = saved_model_dict['guide']\n",
        "pyro.get_param_store().load(model_path + \"\\model_01_params.pt\") # model #1 in the path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcMyqXVQR7l2"
      },
      "source": [
        "**Define utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "04cayGzoe4zC"
      },
      "outputs": [],
      "source": [
        "def give_uncertainities(x, num_samples=1):\n",
        "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
        "    yhats = [F.log_softmax(model(x).data, dim=1) for model in sampled_models]\n",
        "    return yhats[0]\n",
        "\n",
        "def compute_evidence(image):\n",
        "    # image = image.unsqueeze(dim=0)\n",
        "    y = give_uncertainities(image)\n",
        "    return y\n",
        "\n",
        "def compute_confidence(evidence):\n",
        "    conf = torch.exp(evidence)\n",
        "    conf = conf / torch.sum(conf) # Do these two operations not amount to a softmax (exp(a_i)/sum(exp(a_i)??\n",
        "    conf_diff = conf.sort().values[0][-1] - conf.sort().values[0][-2]\n",
        "    return conf_diff, conf\n",
        "\n",
        "\n",
        "def decide(image, threshold=10):\n",
        "    rt = 0\n",
        "    max_evidence, total_evidence = 0, 0\n",
        "    while max_evidence < threshold:\n",
        "      evidence = torch.exp(compute_evidence(image)) # These are softmax predictions (e^log_softmax = softmax)\n",
        "      total_evidence = total_evidence + evidence # evidence only increases\n",
        "      max_evidence = torch.max(total_evidence)\n",
        "      rt = rt + 1 # Increase sampling step\n",
        "    choice = torch.argmax(total_evidence)\n",
        "    confidence, confidence_array = compute_confidence(total_evidence)\n",
        "    return int(choice.cpu().numpy()), rt, float(confidence.cpu().numpy()), confidence_array.cpu().numpy()\n",
        "\n",
        "def save_df(index, Choice, RT, Confidence, Threshold, Noise, Labels, image_stats, path):\n",
        "    # unpack image stats\n",
        "    noise_max, noise_mean, image_max, image_mean, noisy_image_max, noisy_image_mean = image_stats\n",
        "\n",
        "    simulations = {'mnist_index': index,\n",
        "                   'choice': Choice,\n",
        "                   'rt': RT,\n",
        "                   'confidence': Confidence,\n",
        "                   'threshold': Threshold,\n",
        "                   'noise': Noise,\n",
        "                   'true label': Labels,\n",
        "                   'noise max': noise_max,\n",
        "                   'noise mean': noise_mean,\n",
        "                   'image max': image_max,\n",
        "                   'image mean': image_mean,\n",
        "                   'noisy_image max': noisy_image_max,\n",
        "                   'noisy_image mean': noisy_image_mean}\n",
        "\n",
        "    df = pd.DataFrame(simulations)\n",
        "    df.to_csv(path)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlYwlVoYAWQn"
      },
      "source": [
        "**Simulations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3u7XgcKC4res"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set the threshold to 3\n",
            "   Set the noise level to 2.1\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the noise level to 2.9\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "Set the threshold to 5\n",
            "   Set the noise level to 2.1\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n",
            "   Set the noise level to 2.9\n",
            "           0\n",
            "           1000\n",
            "           2000\n",
            "           3000\n",
            "           4000\n",
            "           5000\n",
            "           6000\n",
            "           7000\n",
            "           8000\n",
            "           9000\n"
          ]
        }
      ],
      "source": [
        "threshold_levels = [3]\n",
        "#noise_levels = [0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]\n",
        "save_path = 'results/noise_level_sims.csv' # path to where you want to save the output\n",
        "all_index, all_choice, all_rt, all_confidence, all_threshold, all_labels, all_ev = [], [], [], [], [], [], []\n",
        "\n",
        "# image statistics lists\n",
        "noise_max, noise_mean, image_max, image_mean, noisy_image_max, noisy_image_mean = [], [], [], [], [], []\n",
        "\n",
        "# Iterate across threshold levels.\n",
        "for a in threshold_levels:\n",
        "  print(\"Set the threshold to {}\".format(str(a)))\n",
        "  # Iterate across levels of evidence strength (ev=evidence factor). 0 = pure noise, 1 = pure evidence\n",
        "  for ev in np.linspace(0, 1, 11): \n",
        "      # Evidence factor\n",
        "      ev = round(ev, 1) # np.linspace can cause rounding errors.\n",
        "      print('   Set the evidence level to {}'.format(str(ev)))\n",
        "      for i, (image, label) in enumerate(test_loader):\n",
        "        # Compute final image as a weighted blend between pure noise and the original image\n",
        "        # Compute noise array\n",
        "        noise_array = torch.rand(image.shape) * image.max() # multiply with the max value to make the noise as strong as the original image.\n",
        "        # Compute final image\n",
        "        noisy_image = ev*image + (1-ev)*noise_array\n",
        "        choice, rt, confidence, _ = decide(noisy_image.to(device), threshold=a)\n",
        "        all_index.append(i)\n",
        "        all_choice.append(choice)\n",
        "        all_rt.append(rt)\n",
        "        all_confidence.append(confidence)\n",
        "        all_threshold.append(a)\n",
        "        all_ev.append(ev)\n",
        "        all_labels.append(int(label.cpu().numpy()))\n",
        "\n",
        "        # image and noise data\n",
        "        noise_max.append(noise_array.max())\n",
        "        noise_mean.append(noise_array.mean())\n",
        "        image_max.append(image[image>0].max()) # Just take the positive non-zero values (the actual pixels belonging to the evidence)\n",
        "        image_mean.append(image[image>0].mean())\n",
        "        noisy_image_max.append(noisy_image.max())\n",
        "        noisy_image_mean.append(noisy_image.mean())\n",
        "        \n",
        "        # Print progress after each 1000 images.\n",
        "        if (i%1000)==0:\n",
        "          print('           {}'.format(str(i)))\n",
        "      \n",
        "      # store image stats in single list\n",
        "      all_image_stats = [noise_max, noise_mean, image_max, image_mean, noisy_image_max, noisy_image_mean]\n",
        "      # Save to file.\n",
        "      save_df(all_index, all_choice, all_rt, all_confidence, all_threshold, all_ev, all_labels, all_image_stats, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Example images with noise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_loader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtest_loader\u001b[49m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Apply noise to image\u001b[39;00m\n\u001b[0;32m      7\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image, label = next(iter(test_loader))\n",
        "\n",
        "# Apply noise to image\n",
        "p = 0.1\n",
        "\n",
        "# The image becomes a blend of pure noise and the original image.\n",
        "noise = torch.rand(image.shape)*image.max()\n",
        "noisy_image = p*image + (1-p)*noise # multiply with the max value to make the noise as strong as the original image.\n",
        "print(f\"Mean of noise: {noise.mean()}\")\n",
        "print(f\"Max of noise: {noise.max()}\")\n",
        "print(f\"Image max value: {image.max()}\")\n",
        "print(f\"Image mean value of positive nonzero values: {image[image>0].mean()}\")\n",
        "print(f\"Image + noise, max: {noisy_image.max()}\")\n",
        "print(f\"Image + noise, mean: {noisy_image.mean()}\")\n",
        "\n",
        "# Plot image\n",
        "plt.imshow(noisy_image.squeeze(), cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.1\n",
            "0.2\n",
            "0.3\n",
            "0.4\n",
            "0.5\n",
            "0.6\n",
            "0.7\n",
            "0.8\n",
            "0.9\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "for noise in np.linspace(0, 1, 11):\n",
        "    print(round(noise, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'range' object is not an iterator",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mTypeError\u001b[0m: 'range' object is not an iterator"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
